{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "import os\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 92.0.4515\n",
      "Get LATEST driver version for 92.0.4515\n",
      "Driver [C:\\Users\\SC\\.wdm\\drivers\\chromedriver\\win32\\92.0.4515.107\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=0\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=10\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=20\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=30\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=40\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=50\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=60\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=70\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=80\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=90\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=100\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=110\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=120\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=130\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=140\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=150\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=160\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=170\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=180\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=190\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=200\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=210\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=220\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=230\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=240\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=250\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=260\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=270\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=280\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=290\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=300\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=310\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=320\n",
      "http://www.indeed.com/jobs?q=data%20engineer&l=California&start=330\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "max_page = 340\n",
    "\n",
    "jobs14 = []\n",
    "companies14 = []\n",
    "locations14 = []\n",
    "summaries14 = []\n",
    "\n",
    "for start in range(0, max_page, 10):\n",
    "    indeed_url = 'http://www.indeed.com/jobs?q=data%20engineer&l=California&start=' + str(start)\n",
    "    browser.visit(indeed_url)\n",
    "    time.sleep(5)  \n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    print(indeed_url)  \n",
    "    \n",
    "    #grabbing job title\n",
    "    #for div in soup.find_all(name='div', attrs={'class':'job_seen_beacon'}):\n",
    "    for td in soup.find_all(name='td', attrs={'class':'resultContent'}):\n",
    "        for div in td.find_all(name='div', attrs={'class':'heading4 color-text-primary singleLineTitle tapItem-gutter'}):\n",
    "            for span in div.find_all(name='span'):\n",
    "                if span.text.strip() != 'new':\n",
    "                    jobs14.append(span.text.strip())  \n",
    "\n",
    "    #grabbing company name\n",
    "    for td2 in soup.find_all(name='td', attrs={'class':'resultContent'}):\n",
    "        for div2 in td2.find_all(name='div', attrs={'class':'heading6 company_location tapItem-gutter'}):\n",
    "            for span2 in div2.find_all(name='span', attrs={'class':'companyName'}):\n",
    "                companies14.append(span2.text.strip())      \n",
    "\n",
    "    #grabbing location\n",
    "    for td3 in soup.find_all(name='td', attrs={'class':'resultContent'}):\n",
    "        for div3 in td3.find_all(name='div', attrs={'class':'heading6 company_location tapItem-gutter'}):\n",
    "            for div4 in div3.find_all(name='div'):\n",
    "                locations14.append(div4.text.strip())   \n",
    "\n",
    "    #grabbing summary text\n",
    "    divs = soup.findAll('div', attrs={'class': 'job-snippet'})\n",
    "    for div5 in divs:\n",
    "        summaries14.append(div5.text.strip())\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Engineer',\n",
       " 'Data Engineer III',\n",
       " 'Data Engineer',\n",
       " 'Associate, Visualization Data Engineer',\n",
       " 'Data Engineer, Growth',\n",
       " 'SQL Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Visualization Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer/ETL Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'L3 Network Data Center Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'L3 Network Data Center Engineer',\n",
       " 'Entry Level - Data Engineer / Data Analyst (STEM)',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer (1043), DataSF',\n",
       " 'Data Engineer, Users and Products',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Associate Data Engineer',\n",
       " 'eCommerce Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Visualization Engineer',\n",
       " 'Data Engineer',\n",
       " 'Sr. Data Engineer, Annotation',\n",
       " 'Associate B-52 Flight Test Engineer – Data Analyst',\n",
       " 'Data Engineer',\n",
       " 'Big Data/Python Engineer - Junior',\n",
       " 'Data Engineer, Analytics (Generalist)',\n",
       " 'Data Engineer',\n",
       " 'Freelance - Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer (Python, SQL hands-on)',\n",
       " 'Sr. Data Engineer',\n",
       " 'Sr Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer Manager',\n",
       " 'Sr. Data Engineer',\n",
       " 'Data Engineer, Data Platform - TikTok-US-Tech Services',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Software Engineer, SaaS Data Protection',\n",
       " 'Data Engineer (Full Time) United States',\n",
       " 'Data Engineer',\n",
       " 'Senior Quality Assurance Engineer - Core Data Services',\n",
       " 'Software Engineer Data Pipeline',\n",
       " 'Data Engineer, Data Platform',\n",
       " 'Data Engineer (Remote)',\n",
       " 'AWS Data Engineer',\n",
       " 'Data Engineer/Analyst',\n",
       " 'Data Engineer - All Levels',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer BI/ETL',\n",
       " 'Data Infrastructure Engineer',\n",
       " 'Sr. Data Engineer',\n",
       " 'Data Engineer, Marketing',\n",
       " 'Senior Machine Learning Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Scientist / Software Engineer (Prognostics)',\n",
       " 'Data Visualization Engineer (Tableau Developer)',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Associate, Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Visualization Data Engineer',\n",
       " 'PySpark Data Engineer, Consultant',\n",
       " 'Data Engineer',\n",
       " 'Big Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Sr. Data Engineer',\n",
       " 'Machine Learning Engineer, Risk Data Mining',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer, Core Growth',\n",
       " 'Data Engineer, Core Growth',\n",
       " 'Sr. Data Engineer',\n",
       " 'Sr. Data/Systems Engineer',\n",
       " 'AWS Data Engineer',\n",
       " 'ML Data Infrastructure Engineer',\n",
       " 'Pyspark Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Science Engineer',\n",
       " 'ML/Data Engineer (NO C2C!!)',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer 1, Product Lifecylce',\n",
       " 'Machine Learning/Data Science Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer - 3786626',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'SSIS Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Analyst/Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Analytics Engineer',\n",
       " 'Senior Full Stack Engineer - Data Visualization',\n",
       " 'Data Engineer, Consultant',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer, Data Platform',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Software Engineer - Data and Simulation',\n",
       " 'Data Engineer [Remote]',\n",
       " 'Data Engineer, Core Automation Services',\n",
       " 'Data Engineer',\n",
       " 'Data Infrastructure Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Reliability Engineer',\n",
       " 'Data Engineer - (B3)',\n",
       " 'Staff Data Engineer',\n",
       " 'Data Science Engineer',\n",
       " 'Data Visualization Engineer',\n",
       " 'Senior Data Warehouse Engineer',\n",
       " 'MMS Data Management Application Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer, Data Platform',\n",
       " 'Data Engineer - (B3)',\n",
       " 'Senior Data Engineer - Remote',\n",
       " 'Data Engineer, Machine Learning',\n",
       " 'AWS Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Software/Data Engineer, RegLab',\n",
       " 'Senior Data Engineer',\n",
       " 'Big Data Engineer',\n",
       " 'Data Visualization Engineer (Tableau Developer)',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer, Senior',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Center Controls Engineer, SCADA',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer, Data Platform',\n",
       " 'Data Engineer',\n",
       " 'Big Data/Python Engineer - Junior',\n",
       " 'Freelance - Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Center Manufacturing Engineer, Standards, Tools and Met...',\n",
       " 'Senior Data Engineer, Business Intelligence',\n",
       " 'Senior Data Analysis Engineer',\n",
       " 'Data Engineer',\n",
       " 'Junior Data Science Engineer (Remote)',\n",
       " 'Sr. Process Engineer I, Data Analytics',\n",
       " 'SENIOR DATA PLATFORM ENGINEER',\n",
       " 'Senior Presales Engineer - Unstructured Data Solutions',\n",
       " 'Senior Data Analytics Engineer (MicroStrategy and SQL)',\n",
       " 'Data Engineer [Remote]',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer - Location Flexible',\n",
       " 'Senior Machine Learning Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer [Remote]',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Sr. Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Freelance - Data Engineer',\n",
       " 'Senior Data Warehouse Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer/Analyst',\n",
       " 'Data Engineer, Machine Learning',\n",
       " 'Data Operations Engineer - Lead',\n",
       " 'Sr. Data/Systems Engineer',\n",
       " 'Data Engineer',\n",
       " 'Big Data Software Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer, Data Platform',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Sr. Process Engineer I, Data Analytics',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data & Analytics Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer, Business Intelligence',\n",
       " 'Software Engineer, Big Data',\n",
       " 'Senior Data/ML Engineer- #7921',\n",
       " 'Senior Data Reliability Engineer',\n",
       " 'Senior Data Analysis Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Machine Learning/Data Science Engineer',\n",
       " 'Senior Data Analysis Engineer',\n",
       " 'Data Engineer (Los Angeles)',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Research Data Engineer',\n",
       " 'Data Analytics Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer, Security & Compliance - Data Platform',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Sr. Reliability Engineer - Data Center',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer, Product Analytics',\n",
       " 'Data Engineer',\n",
       " 'Sr. Security Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer I',\n",
       " 'Data Engineer',\n",
       " 'Software Engineer - Data and Simulation',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer (BIG DATA / HADOOP)',\n",
       " 'Senior Data Engineer',\n",
       " 'Lead Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Warehouse Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Machine Learning Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Analysis Engineer',\n",
       " 'Healthcare Data Engineer',\n",
       " 'Fullstack Engineer - Data Tools',\n",
       " 'Data Modeling Engineer (Remote)',\n",
       " 'Senior Software Engineer (Data Replication) -Remote',\n",
       " 'Data Engineer-Data Platform',\n",
       " 'Lead Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Sr Python & SQL(ETL) Data Engineer',\n",
       " 'Data Modeling Engineer (Remote)',\n",
       " 'Software Engineer - Data Lake',\n",
       " 'Senior Data Engineer (Series D Startup)',\n",
       " 'Data Engineer',\n",
       " 'Data Analyst / Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Analytics Engineer (Remote Friendly)',\n",
       " 'Data Center NAND SSD Product Development Engineer - SK',\n",
       " 'Software Engineer - Ads Data',\n",
       " 'Software Engineer - Data and Simulation',\n",
       " 'Senior Data Warehouse Engineer',\n",
       " 'Sr. Data Engineer - Microservices',\n",
       " 'Data Center Capacity Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Jr. Data Engineer, Marketing Analytics',\n",
       " 'Data Engineer',\n",
       " 'Lead Data Engineer - 180',\n",
       " 'Data Engineer - Data Platform',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Associate Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Site Reliability Engineer - Ads Data',\n",
       " 'Backend Engineer - Data Platform (Remix by Via)',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Remote ETL Data Engineer',\n",
       " 'Data Center Capacity Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Platform Engineer',\n",
       " 'Software Engineer - Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Software Engineer - Data Mining, Machine Learning',\n",
       " 'Software Engineer, Global Data Warehouse',\n",
       " 'Data Engineer',\n",
       " 'Software Engineer, Data Warehousing',\n",
       " 'Senior Cloud Data Engineer',\n",
       " 'Software Engineer - Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Visualization Engineer (Tableau Developer)',\n",
       " 'Senior Data Engineer [Remote]',\n",
       " 'Senior Data Engineer',\n",
       " 'Freelance - Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Principal UI Engineer, Data Visualization',\n",
       " 'Senior Software Engineer, Data Abstraction Platform',\n",
       " 'Data Engineer - Data Platform',\n",
       " 'Developer Technology Engineer, Data Analytics - New College...',\n",
       " 'Associate Data Engineer',\n",
       " 'Data Engineer, Product Analytics',\n",
       " 'Fullstack Software Development Engineer - Public Data Engine...',\n",
       " 'Data Engineer',\n",
       " 'Backend Software Engineer - Data Storage',\n",
       " 'PySpark Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Center Network Test Engineer',\n",
       " 'Data Engineer - W1753',\n",
       " 'Software Engineer, Data Infrastructure',\n",
       " 'Data Engineer - Remote',\n",
       " 'Senior Software Engineer - SaaS Data Protection',\n",
       " 'Data Science Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer - Project Delivery Specialist',\n",
       " 'Lead Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Solutions Engineer, Data Science',\n",
       " 'Sr. Data Engineer / Data Analyst, Tesla Product Engineering',\n",
       " 'Software Engineer - Big Data',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Software Engineer - Data Products',\n",
       " 'Principal Data Engineer',\n",
       " 'Data Visualization / Experience Design Engineer',\n",
       " 'Staff Software Engineer, Data Connections',\n",
       " 'Data Center NAND SSD Product Development Engineer - SK',\n",
       " 'Pre-Sales Engineer, Data Center - SoCal',\n",
       " 'Data Analytics Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer, GMS',\n",
       " 'NASA Data Systems Test and Software Operations Support Engin...',\n",
       " 'Senior Data Engineer',\n",
       " 'Principal Data Engineer',\n",
       " 'Data Scientist / Data Engineer',\n",
       " 'Software Engineer - Data',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Solutions Engineer',\n",
       " 'Senior Data Engineer - Prediction and Behavior Modeling',\n",
       " 'Senior Data Engineer (BIG DATA / HADOOP)',\n",
       " 'Senior Data Engineer',\n",
       " 'Chief Engineer, Data Center',\n",
       " 'Software Engineer - Ads Data',\n",
       " 'Data Engineer',\n",
       " 'Data / ETL Engineer with Python',\n",
       " 'Backend/Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Science Engineer',\n",
       " 'Sr. Data Engineer SDI + Hana',\n",
       " 'Data Science - Analytics Engineer',\n",
       " 'Software Engineer, Data Infrastructure',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Software Engineer, Data',\n",
       " 'Lead Data Engineer',\n",
       " 'Principal Data Engineer',\n",
       " 'Software Engineer - Data',\n",
       " 'Sr. Data/Systems Engineer',\n",
       " 'Software Engineer - Big Data',\n",
       " 'Data Engineer II',\n",
       " 'Software Engineer - Data',\n",
       " 'Data Engineer',\n",
       " 'Energy Service Data Infrastructure Engineer',\n",
       " 'Data Engineer',\n",
       " 'Return to Work - Data Engineer, Analytics',\n",
       " 'Data Analytics Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer- Data Streaming',\n",
       " 'Big Data Engineer',\n",
       " 'Lead Software Engineer, Core Data',\n",
       " 'Software Engineer - Ads Data',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Sr Python & SQL(ETL) Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Backend/Data Engineer',\n",
       " 'Data Center Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer II (Remote)',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer - Data Product Development, Loyalty and...',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Center Manufacturing Engineer, Standards, Tools and Met...',\n",
       " 'Sr. Big Data Engineer',\n",
       " 'Staff Data Engineer',\n",
       " 'Senior Data Software Engineer',\n",
       " 'Principal Data Platform Software Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'GNC Infrastructure & Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Sr Python & SQL(ETL) Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Senior Data Engineer - Machine Learning',\n",
       " 'Backend/Data Engineer',\n",
       " 'Senior Data Engineer, Machine Learning',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Lead Data Engineer',\n",
       " 'Associate Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Sr Python & SQL(ETL) Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Software Engineer, Data',\n",
       " 'Sr. Data Engineer',\n",
       " 'Sr. Data Engineer (Data Quality & Insights)',\n",
       " 'Principal UI Engineer, Data Visualization',\n",
       " 'Software Engineer, Data Products',\n",
       " 'Staff Data Engineer',\n",
       " 'Sr. Associate Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Software Engineer - Data Infrastructure - Public Cloud',\n",
       " 'Staff Software Engineer, Data',\n",
       " 'Data Engineer',\n",
       " 'Data Scientist / Data Engineer',\n",
       " 'NASA Data Systems Test and Software Operations Support Engin...',\n",
       " 'Data Engineer',\n",
       " 'Data Science Engineer (AI)',\n",
       " 'Software Engineer - Data Mining, Machine Learning',\n",
       " 'Senior Software Engineer - SaaS Data Protection',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Staff Software Engineer, Data Connections',\n",
       " 'Senior Software Engineer, Core Data Platform',\n",
       " 'Data Science - Analytics Engineer',\n",
       " 'Principal Data Engineer',\n",
       " 'Principal Data Engineer',\n",
       " 'Data Center NAND SSD Product Development Engineer - SK',\n",
       " 'Sr Python & SQL(ETL) Data Engineer',\n",
       " 'Data Scientist / Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Data Ops Engineer - Remote',\n",
       " 'Staff Software Engineer, Data Connections',\n",
       " 'Senior Data Engineer',\n",
       " 'Sr. Data Engineer',\n",
       " 'Senior Data Engineer - Scala/Spark/SQL',\n",
       " 'Software Engineer, Data',\n",
       " 'Sr Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Principal Engineer, Data Platform',\n",
       " 'Data Engineer',\n",
       " 'Sr Data Engineer (Content Metadata)',\n",
       " 'Lead Data Platform Engineer',\n",
       " 'Staff Software Engineer, Data',\n",
       " 'Senior Data Engineer, Machine Learning',\n",
       " 'Data Center NAND SSD Product Development Engineer - SK',\n",
       " 'Senior Data Engineer - SQL, AWS, Python',\n",
       " 'Data Engineer',\n",
       " 'Principal Data Engineer',\n",
       " 'Software Engineer - Data Infrastructure',\n",
       " 'Senior Solutions Engineer, Data Science',\n",
       " 'Software Engineer - Ads Data',\n",
       " 'Senior Data Platform Engineer',\n",
       " 'Data Engineer',\n",
       " 'Cloud Data Engineer',\n",
       " 'Backend/Data Engineer',\n",
       " 'Senior Data Analytics Engineer',\n",
       " 'Data Engineer II, Fintech',\n",
       " 'Data Engineer, Machine Learning',\n",
       " 'Data Scientist / ML Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer',\n",
       " 'Staff Software Engineer - Data Platform',\n",
       " 'Sr. Data Engineer',\n",
       " 'Associate, Data Engineer',\n",
       " 'Staff Software Engineer, Data',\n",
       " 'Principal Data Engineer, JLL Technologies',\n",
       " 'Sr. Data Center Infrastructure Engineer',\n",
       " 'Data Center Facilities Engineering, Systems Engineer',\n",
       " 'Data Science - Analytics Engineer',\n",
       " 'Software Engineer, Data Engineering']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Synaptein Solutions',\n",
       " 'Ursus',\n",
       " 'Harnham',\n",
       " 'KPMG',\n",
       " 'Square',\n",
       " 'Thermo Fisher Scientific',\n",
       " 'Navis',\n",
       " 'Deckers Brands',\n",
       " 'Unicorn Technologies, LLC',\n",
       " 'Kaiser Permanente',\n",
       " 'CDM search',\n",
       " 'Best High technologies',\n",
       " 'Yochana IT inc',\n",
       " 'Visa',\n",
       " 'Rangam Consultants Inc.',\n",
       " 'Visa',\n",
       " 'Rangam Consultants Inc.',\n",
       " 'PCS Global Tech',\n",
       " 'Hive',\n",
       " 'City and County of San Francisco',\n",
       " 'Google',\n",
       " 'Projas Technologies',\n",
       " 'NextEra Energy',\n",
       " 'Facebook',\n",
       " 'Red Bull',\n",
       " 'PG&E Corporation',\n",
       " 'PepsiCo',\n",
       " 'Johnson & Johnson Family of Companies',\n",
       " 'Awning',\n",
       " 'Visa',\n",
       " 'Verana Health',\n",
       " 'Kinect',\n",
       " 'Rivian Automotive',\n",
       " 'BOEING',\n",
       " 'Transcend Digital',\n",
       " 'Bloom Energy',\n",
       " 'Facebook',\n",
       " 'Engage3',\n",
       " 'Saatchi & Saatchi (We Are Saatchi)',\n",
       " 'Tesla',\n",
       " 'Kani Solutions Inc.',\n",
       " 'Betterfuture solutions',\n",
       " 'Tesla',\n",
       " 'Brillio',\n",
       " 'Osmind',\n",
       " 'Snapchat',\n",
       " 'Callaway Golf Company',\n",
       " 'TikTok',\n",
       " 'Kollasoft Inc',\n",
       " 'TikTok',\n",
       " 'Rubrik Job Board',\n",
       " 'Cisco Systems',\n",
       " 'SIS',\n",
       " 'Live Nation',\n",
       " 'Rapid7',\n",
       " 'Peloton',\n",
       " 'Wurl, Inc',\n",
       " 'Infostretch Corporation',\n",
       " 'Proofpoint',\n",
       " 'FanDuel',\n",
       " 'Saama Technologies Inc',\n",
       " 'RIOS Intelligent Machines, Inc.',\n",
       " 'Ironclad, Inc.',\n",
       " 'eCivis',\n",
       " 'Cisco Systems',\n",
       " 'sweetgreen',\n",
       " 'Square',\n",
       " 'Moveworks',\n",
       " 'KPI Partners',\n",
       " 'SZ Media',\n",
       " 'Tesla',\n",
       " 'Luxoft',\n",
       " 'HCL Technologies',\n",
       " 'IT Hub Inc.',\n",
       " 'Petco',\n",
       " 'Johnson Controls',\n",
       " 'KPMG',\n",
       " 'Deloitte',\n",
       " 'Activision',\n",
       " 'Deloitte',\n",
       " 'SS&C Technologies',\n",
       " 'Adobe',\n",
       " 'Panasonic Corporation of North America',\n",
       " 'AltaMed Health Services Corporation',\n",
       " 'Sharecare Inc.',\n",
       " 'TikTok',\n",
       " 'Reformation',\n",
       " 'NBCUniversal',\n",
       " 'Obsidian Security',\n",
       " 'Snapchat',\n",
       " 'Snapchat',\n",
       " 'Roku',\n",
       " 'Tesla',\n",
       " 'AUTOCONTENT',\n",
       " 'Aluna',\n",
       " 'Frontend Arts Inc',\n",
       " 'LatentView Analytics',\n",
       " 'Bytedance',\n",
       " 'Network Capital Funding Corporation',\n",
       " 'Morecommerce',\n",
       " 'Ancestry',\n",
       " 'Braintrust',\n",
       " 'Techwave Consulting Inc.',\n",
       " 'Slalom Consulting',\n",
       " 'Illumina',\n",
       " 'Salesforce',\n",
       " 'California State University',\n",
       " 'Accenture',\n",
       " 'SquareTrade',\n",
       " 'Happiest Baby, Inc.',\n",
       " 'MetroSys',\n",
       " 'REX',\n",
       " 'MT Global US INC',\n",
       " 'Stanford Health Care',\n",
       " 'OpenTable',\n",
       " 'Spin',\n",
       " 'Blue Shield of California',\n",
       " 'Sundae',\n",
       " 'Peloton',\n",
       " 'motivity Labs',\n",
       " 'motivity Labs',\n",
       " 'AmeriHome Mortgage',\n",
       " 'Xwing',\n",
       " 'Blue Owl',\n",
       " 'Tesla',\n",
       " 'UJET',\n",
       " 'Johnson & Johnson Family of Companies',\n",
       " 'CK Franchising, Inc.',\n",
       " 'Screen Actors Guild- Producers Pension & Health...',\n",
       " 'Dovenmuehle',\n",
       " 'Edmunds.com',\n",
       " 'Hulu',\n",
       " 'Applied Materials Inc.',\n",
       " 'ServiceNow',\n",
       " 'Andreessen Horowitz',\n",
       " 'Verana Health',\n",
       " 'sweetgreen',\n",
       " 'Hitachi ABB Power Grids',\n",
       " 'Brillio',\n",
       " 'Peloton',\n",
       " 'Applied Materials Inc.',\n",
       " 'Toptal',\n",
       " 'Motional',\n",
       " 'Infostretch Corporation',\n",
       " 'Synthego',\n",
       " 'Stanford University',\n",
       " 'Commure',\n",
       " 'Adobe',\n",
       " 'Luxoft',\n",
       " 'Thermo Fisher Scientific',\n",
       " 'Amazon Web Services, Inc.',\n",
       " 'Mainspring Energy',\n",
       " 'Network Capital Funding Corporation',\n",
       " 'Jobox.ai',\n",
       " 'Chartboost',\n",
       " 'Levi Strauss & Co.',\n",
       " 'First Tech Federal Credit Union',\n",
       " 'Ontic',\n",
       " 'Milliman',\n",
       " 'Google',\n",
       " 'AltaMed Health Services Corporation',\n",
       " 'Peloton',\n",
       " 'Twilio',\n",
       " 'Bloom Energy',\n",
       " 'Saatchi & Saatchi (We Are Saatchi)',\n",
       " 'UJET',\n",
       " 'Google',\n",
       " 'Square',\n",
       " 'light.io',\n",
       " 'Bytedance',\n",
       " 'Wurl, Inc',\n",
       " 'Kite Pharma',\n",
       " 'Harnham',\n",
       " 'Dell Technologies',\n",
       " 'TrueCar, Inc.',\n",
       " 'Blue Owl',\n",
       " 'Headspace',\n",
       " 'Happiest Baby, Inc.',\n",
       " 'LaunchDarkly',\n",
       " 'Dropbox',\n",
       " 'Moveworks',\n",
       " 'Headspace',\n",
       " 'Chartboost',\n",
       " 'Blue Owl',\n",
       " 'Levi Strauss & Co.',\n",
       " 'Screen Actors Guild- Producers Pension & Health...',\n",
       " 'Twilio',\n",
       " 'Roku',\n",
       " 'Brillio',\n",
       " 'Replica',\n",
       " 'Saatchi & Saatchi (We Are Saatchi)',\n",
       " 'Apixio',\n",
       " 'Carrum Health',\n",
       " 'Thermo Fisher Scientific',\n",
       " 'Motional',\n",
       " 'Genentech',\n",
       " 'Tesla',\n",
       " 'Levi Strauss & Co.',\n",
       " 'HP',\n",
       " 'Tradesy',\n",
       " 'Logic20/20',\n",
       " 'Peloton',\n",
       " 'Inspire',\n",
       " 'BXGI',\n",
       " 'Twilio',\n",
       " '8k Miles',\n",
       " 'RPM Mortgage, Inc.',\n",
       " 'Kite Pharma',\n",
       " 'NTENT',\n",
       " 'HOVER',\n",
       " 'Williams Sonoma',\n",
       " 'Cedars-Sinai',\n",
       " 'Square',\n",
       " 'TikTok',\n",
       " 'Fanatics Inc.',\n",
       " 'Hulu',\n",
       " 'Light Labs, Inc.',\n",
       " 'LaunchDarkly',\n",
       " 'NTENT',\n",
       " 'Cowbell Cyber Inc.',\n",
       " 'Sia Partners',\n",
       " 'Intercom',\n",
       " 'Two Chairs',\n",
       " 'Headspace',\n",
       " 'AltaMed Health Services Corporation',\n",
       " 'Metromile',\n",
       " 'Headspace',\n",
       " 'Logic20/20',\n",
       " 'Milliman',\n",
       " 'Salesforce',\n",
       " 'Light Labs, Inc.',\n",
       " 'HomeLister',\n",
       " 'CourseKey',\n",
       " 'Fox Corporation',\n",
       " 'Oura',\n",
       " 'OpenTable',\n",
       " 'Airtable',\n",
       " 'Convex Tech',\n",
       " 'TikTok',\n",
       " 'Havas Media',\n",
       " 'LendUS LLC',\n",
       " 'Tesla',\n",
       " 'Lineage Logistics',\n",
       " 'Kollasoft Inc',\n",
       " 'Facebook',\n",
       " 'REX',\n",
       " 'Workday',\n",
       " 'Avetta, LLC',\n",
       " 'Park Place Technologies',\n",
       " 'CourseKey',\n",
       " 'Xwing',\n",
       " 'Hazel Health',\n",
       " 'Visa',\n",
       " 'Two Chairs',\n",
       " 'Virgin Orbit',\n",
       " 'Two Chairs',\n",
       " 'Hazel Health',\n",
       " 'Apixio',\n",
       " 'HOVER',\n",
       " '8k Miles',\n",
       " 'Grid Dynamics',\n",
       " 'Toyota Research Institute',\n",
       " 'BXGI',\n",
       " 'Hemisphere Media Group',\n",
       " 'Komodo Health',\n",
       " 'Light Labs, Inc.',\n",
       " 'Amino, Inc.',\n",
       " 'Twitch',\n",
       " 'Fractal.ai',\n",
       " 'PingCAP',\n",
       " 'TikTok',\n",
       " 'Chipotle',\n",
       " 'Betterview',\n",
       " 'Axos Bank',\n",
       " 'ServiceNow',\n",
       " 'Fractal.ai',\n",
       " 'Exabeam',\n",
       " 'Recruiting From Scratch',\n",
       " '8k Miles',\n",
       " 'Alphataraxia',\n",
       " 'WarnerMedia',\n",
       " 'Hemisphere Media Group',\n",
       " 'Vouch Insurance',\n",
       " 'Intel',\n",
       " 'TikTok',\n",
       " 'Xwing',\n",
       " 'Apixio',\n",
       " 'Enquero Inc',\n",
       " 'Facebook',\n",
       " 'Albert',\n",
       " 'Benefit Cosmetics',\n",
       " 'Grid Dynamics',\n",
       " 'Rocket Lawyer',\n",
       " 'Tesla',\n",
       " 'REX',\n",
       " 'Reformation',\n",
       " 'Hive Media Group',\n",
       " 'Sprig',\n",
       " 'Hemisphere Media Group',\n",
       " 'TikTok',\n",
       " 'Via',\n",
       " 'EZ Texting',\n",
       " 'Airbnb',\n",
       " 'First Tech Federal Credit Union',\n",
       " 'Insight Global',\n",
       " 'Facebook',\n",
       " 'Hemisphere Media Group',\n",
       " 'DUOPEAK',\n",
       " 'Willow Innovations',\n",
       " 'EarnUp',\n",
       " 'Transform Data',\n",
       " 'Bolt',\n",
       " 'Motional',\n",
       " 'Uber',\n",
       " '8k Miles',\n",
       " 'Blizzard Entertainment',\n",
       " 'Deloitte',\n",
       " 'Transform Data',\n",
       " \"The World's Largest Social Network\",\n",
       " 'Luxoft',\n",
       " 'HiRoad',\n",
       " 'Together Labs',\n",
       " 'Saatchi & Saatchi (We Are Saatchi)',\n",
       " 'EZ Texting',\n",
       " 'Workday',\n",
       " 'Netflix',\n",
       " 'Tesla',\n",
       " 'NVIDIA',\n",
       " 'Hive Media Group',\n",
       " 'Facebook',\n",
       " 'Zillow Group',\n",
       " 'Jobox.ai',\n",
       " 'Commure',\n",
       " 'Logic20/20',\n",
       " 'Sprig',\n",
       " 'Cowbell Cyber Inc.',\n",
       " 'HackerRank',\n",
       " 'Facebook',\n",
       " 'Nisum',\n",
       " 'Square',\n",
       " 'Experian',\n",
       " 'Rubrik Job Board',\n",
       " 'Andreessen Horowitz',\n",
       " 'Zefr',\n",
       " 'Snapchat',\n",
       " 'MOLOCO',\n",
       " 'Deloitte',\n",
       " 'Virgin Orbit',\n",
       " 'LPL Financial',\n",
       " 'The Trade Desk',\n",
       " 'Tesla',\n",
       " 'U.S. Bank',\n",
       " 'Slalom Consulting',\n",
       " 'Resiliency LLC',\n",
       " 'Mendel',\n",
       " 'Discord',\n",
       " 'Ad Hoc Team',\n",
       " 'Visa',\n",
       " 'Amplitude',\n",
       " 'Intel',\n",
       " 'Lenovo',\n",
       " 'PARACHUTE HOME',\n",
       " 'Natera',\n",
       " 'Ipsos North America',\n",
       " 'Seasoned',\n",
       " 'Facebook',\n",
       " 'HX5',\n",
       " 'Natera',\n",
       " 'Shutterfly',\n",
       " 'DeepMap, Inc',\n",
       " 'Obsidian Security',\n",
       " 'TaskRabbit',\n",
       " 'Wayfair',\n",
       " 'Motional',\n",
       " 'Visa',\n",
       " 'HOVER',\n",
       " 'Able Services',\n",
       " 'Bytedance',\n",
       " 'CourseKey',\n",
       " 'Ingenworks',\n",
       " 'Verkada',\n",
       " 'Fast AF',\n",
       " 'Medtronic',\n",
       " 'QuantumBricks',\n",
       " 'Resonance AI',\n",
       " 'Airtable',\n",
       " 'MOLOCO',\n",
       " 'Hemisphere Media Group',\n",
       " 'Eureka',\n",
       " 'FabFitFun',\n",
       " 'Disney Streaming Services',\n",
       " 'Obsidian Security',\n",
       " 'Tesla',\n",
       " 'U.S. Bank',\n",
       " 'Silicon Valley Bank',\n",
       " 'Wing',\n",
       " 'Triplebyte',\n",
       " 'Tesla',\n",
       " 'Fox Corporation',\n",
       " 'Facebook',\n",
       " 'PARACHUTE HOME',\n",
       " 'Morecommerce',\n",
       " 'Pluto TV',\n",
       " 'Bloom Energy',\n",
       " '6sense',\n",
       " 'Bytedance',\n",
       " 'Fast AF',\n",
       " 'Parkside',\n",
       " 'Twitch',\n",
       " 'ServiceNow',\n",
       " \"The World's Fastest Growing Rideshare Company\",\n",
       " 'Natera',\n",
       " 'Verkada',\n",
       " 'New Millenium Consulting',\n",
       " 'Rockstar Games',\n",
       " 'GoGuardian',\n",
       " 'Ontic',\n",
       " 'Visa',\n",
       " 'The Walt Disney Company (Corporate)',\n",
       " 'Google',\n",
       " 'QuantumBricks',\n",
       " 'Dolby',\n",
       " 'Course Hero',\n",
       " 'Clari',\n",
       " 'Fox Corporation',\n",
       " 'SureCo',\n",
       " 'Archer',\n",
       " 'Pluralsight',\n",
       " 'LPL Financial',\n",
       " 'ServiceNow',\n",
       " 'Digit',\n",
       " 'Samsara',\n",
       " 'Verkada',\n",
       " 'Flock Freight',\n",
       " '8k Miles',\n",
       " 'Hazel Health',\n",
       " 'Virgin Orbit',\n",
       " 'Hive Media Group',\n",
       " 'Ontic',\n",
       " 'Netskope',\n",
       " 'ServiceNow',\n",
       " 'AltaMed Health Services Corporation',\n",
       " 'Mercari',\n",
       " 'Finix Payments',\n",
       " 'Auction.com',\n",
       " 'Workday',\n",
       " 'Square',\n",
       " 'Dolby',\n",
       " 'Workday',\n",
       " 'Aktify',\n",
       " 'JPMorgan Chase Bank, N.A.',\n",
       " 'Robinhood',\n",
       " 'Resiliency LLC',\n",
       " 'DeepMap, Inc',\n",
       " 'HX5',\n",
       " 'FutureSoft IT',\n",
       " 'Glacier',\n",
       " 'Motional',\n",
       " 'Rubrik Job Board',\n",
       " '8k Miles',\n",
       " 'Digit',\n",
       " 'Amplitude',\n",
       " 'Netflix',\n",
       " 'Transform Data',\n",
       " 'Albert',\n",
       " 'Albert',\n",
       " 'Intel',\n",
       " 'ServiceNow',\n",
       " 'DeepMap, Inc',\n",
       " 'Aktify',\n",
       " 'Retina.ai',\n",
       " 'Amplitude',\n",
       " 'Komodo Health',\n",
       " 'Thermo Fisher Scientific',\n",
       " 'Hewlett Packard Enterprise',\n",
       " 'Mercari',\n",
       " 'Tesla',\n",
       " 'Trianz',\n",
       " 'Valo Health',\n",
       " 'FutureSoft IT',\n",
       " 'WarnerMedia',\n",
       " 'Philo',\n",
       " 'Robinhood',\n",
       " 'Flock Freight',\n",
       " 'Intel',\n",
       " 'CyberCoders',\n",
       " 'Fox Corporation',\n",
       " 'Albert',\n",
       " 'Resonance AI',\n",
       " 'The Trade Desk',\n",
       " 'Bytedance',\n",
       " 'EasyPost',\n",
       " 'MOLOCO',\n",
       " 'cloudteam',\n",
       " 'Verkada',\n",
       " 'Panther Labs',\n",
       " 'Uber',\n",
       " 'Cadence Design Systems',\n",
       " 'INFISWIFT TECHNOLOGIES',\n",
       " 'Parkside',\n",
       " 'HackerRank',\n",
       " 'Discord',\n",
       " 'Finix Payments',\n",
       " 'KPMG',\n",
       " 'Robinhood',\n",
       " 'JLL',\n",
       " 'Zscaler',\n",
       " 'Facebook',\n",
       " 'Resonance AI',\n",
       " 'Neuralink']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thousand Oaks, CA',\n",
       " 'Menlo Park, CA 94025+1 location',\n",
       " 'San Francisco, CA+1 location',\n",
       " 'Los Angeles, CA 90071 (Downtown area)',\n",
       " 'San Francisco, CA',\n",
       " 'Carlsbad, CA 92008',\n",
       " 'Oakland, CA',\n",
       " 'Goleta, CA 93117',\n",
       " 'Oakland, CA•Temporarily Remote',\n",
       " 'Oakland, CA',\n",
       " 'Berkeley, CA 94701•Remote',\n",
       " 'San Jose, CA•Temporarily Remote',\n",
       " 'San Francisco, CA•Temporarily Remote',\n",
       " 'Foster City, CA',\n",
       " 'Menlo Park, CA•Remote',\n",
       " 'Foster City, CA',\n",
       " 'Menlo Park, CA•Remote',\n",
       " 'Poway, CA•Temporarily Remote',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco, CA 94102 (Downtown area)•Temporarily Remote',\n",
       " 'Mountain View, CA',\n",
       " 'San Jose, CA 95126 (Downtown area)•Temporarily Remote',\n",
       " 'San Francisco, CA 94108 (Financial District area)',\n",
       " 'Menlo Park, CA 94025+1 location',\n",
       " 'Santa Monica, CA',\n",
       " 'San Francisco, CA 94105 (Financial District area)',\n",
       " 'Palo Alto, CA 94306 (Ventura area)',\n",
       " 'San Francisco, CA (South Beach area)+6 locations',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Foster City, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Venice, CA 90291+1 location',\n",
       " 'Palo Alto, CA+1 location',\n",
       " 'Edwards AFB, CA',\n",
       " 'Los Angeles, CA•Remote',\n",
       " 'San Jose, CA 95134 (North San Jose area)',\n",
       " 'Burlingame, CA 94010+3 locations',\n",
       " 'Davis, CA',\n",
       " 'El Segundo, CA 90245',\n",
       " 'Fremont, CA',\n",
       " 'Los Angeles, CA•Temporarily Remote',\n",
       " 'Foster City, CA 94404',\n",
       " 'Lathrop, CA',\n",
       " 'Santa Clara, CA 95054',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Los Angeles, CA 90291 (Venice area)',\n",
       " 'Carlsbad, CA 92008 (North Beach area)',\n",
       " 'Mountain View, CA',\n",
       " 'Fremont, CA 94555 (Ardenwood area)',\n",
       " 'Mountain View, CA',\n",
       " 'Palo Alto, CA+1 location',\n",
       " 'San Jose, CA',\n",
       " 'Austin, CA',\n",
       " 'Los Angeles, CA 90012',\n",
       " 'San Francisco, CA 94103 (South of Market area)•Temporarily Remote',\n",
       " 'Santa Clara, CA',\n",
       " 'California•Remote',\n",
       " 'Santa Clara, CA 95054',\n",
       " 'Sunnyvale, CA 94085',\n",
       " 'Los Angeles, CA 90045 (Westchester area)',\n",
       " 'Campbell, CA 95008',\n",
       " 'San Francisco Bay Area, CA',\n",
       " 'San Francisco, CA',\n",
       " 'Pasadena, CA 91103 (West Central area)',\n",
       " 'San Jose, CA',\n",
       " 'California•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'Mountain View, CA',\n",
       " 'Newark, CA 94560•Temporarily Remote',\n",
       " 'Burbank, CA',\n",
       " 'Palo Alto, CA',\n",
       " 'Oakland, CA',\n",
       " 'Sunnyvale, CA•Temporarily Remote',\n",
       " 'Long Beach, CA 90822',\n",
       " 'San Diego, CA 92127 (Rancho Bernardo area)',\n",
       " 'San Jose, CA',\n",
       " 'Irvine, CA 92618+2 locations',\n",
       " 'San Jose, CA 95113 (Downtown area)',\n",
       " 'Santa Monica, CA',\n",
       " 'Los Angeles, CA 90013 (Downtown area)+5 locations',\n",
       " 'San Francisco, CA 94104 (Financial District area)',\n",
       " 'San Jose, CA',\n",
       " 'Palo Alto, CA',\n",
       " 'Montebello, CA 90640•Remote',\n",
       " 'Palo Alto, CA 94301 (Professorville area)',\n",
       " 'Mountain View, CA',\n",
       " 'Vernon, CA',\n",
       " 'List, CA+1 location',\n",
       " 'Newport Beach, CA 92660+1 location',\n",
       " 'Los Angeles, CA 90291 (Venice area)',\n",
       " 'Los Angeles, CA 90291 (Venice area)',\n",
       " 'San Jose, CA',\n",
       " 'Fremont, CA',\n",
       " 'Irvine, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Carlsbad, CA',\n",
       " 'San Jose, CA•Temporarily Remote',\n",
       " 'Mountain View, CA',\n",
       " 'Irvine, CA',\n",
       " 'Chico, CA',\n",
       " 'San Francisco, CA 94107 (South Beach area)',\n",
       " 'San Francisco, CA 94147 (Marina area)•Remote',\n",
       " 'San Diego, CA 92101',\n",
       " 'Silicon Valley, CA+1 location',\n",
       " 'San Diego, CA',\n",
       " 'Palo Alto, CA 94301 (Downtown North area)+1 location',\n",
       " 'San Diego, CA',\n",
       " 'Walnut Creek, CA+5 locations',\n",
       " 'San Francisco, CA',\n",
       " 'Los Angeles, CA 90016',\n",
       " 'Santa Barbara, CA',\n",
       " 'Woodland Hills, CA 91367',\n",
       " 'Foster City, CA 94404',\n",
       " 'Palo Alto, CA 94303',\n",
       " 'Los Angeles, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Oakland, CA',\n",
       " 'California•Remote',\n",
       " 'Santa Clara, CA',\n",
       " 'San Francisco Bay Area, CA•Temporarily Remote',\n",
       " 'San Francisco Bay Area, CA•Temporarily Remote',\n",
       " 'Thousand Oaks, CA',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Fremont, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Redwood City, CA 94065 (Dolphin area)+1 location',\n",
       " 'Irvine, CA 92614',\n",
       " 'Burbank, CA',\n",
       " 'San Francisco, CA 94110 (Mission area)',\n",
       " 'Santa Monica, CA 90404 (Mid-City area)•Remote',\n",
       " 'Santa Monica, CA',\n",
       " 'Santa Clara, CA',\n",
       " 'Santa Clara, CA 95054',\n",
       " 'Menlo Park, CA 94025',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'California•Remote',\n",
       " 'San Jose, CA',\n",
       " 'Santa Clara, CA 95054',\n",
       " 'Santa Clara, CA',\n",
       " 'Santa Clara, CA',\n",
       " 'San Francisco, CA 94104 (Financial District area)+1 location•Remote',\n",
       " 'Santa Monica, CA',\n",
       " 'Santa Clara, CA 95054',\n",
       " 'Menlo Park, CA 94025•Temporarily Remote',\n",
       " 'Stanford, CA',\n",
       " 'San Francisco, CA',\n",
       " 'San Jose, CA',\n",
       " 'Oakland, CA',\n",
       " 'Carlsbad, CA 92008+1 location',\n",
       " 'East Palo Alto, CA',\n",
       " 'Menlo Park, CA 94025',\n",
       " 'Irvine, CA',\n",
       " 'California•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco, CA (North Waterfront area)',\n",
       " 'San Jose, CA 95134 (North San Jose area)',\n",
       " 'Chatsworth, CA 91311',\n",
       " 'San Diego, CA 92128 (Rancho Bernardo area)•Remote',\n",
       " 'Sunnyvale, CA (Lakewood area)',\n",
       " 'Montebello, CA 90640•Remote',\n",
       " 'Santa Clara, CA',\n",
       " 'California•Remote',\n",
       " 'San Jose, CA 95134 (North San Jose area)',\n",
       " 'El Segundo, CA 90245',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco, CA',\n",
       " 'Redwood City, CA',\n",
       " 'Mountain View, CA',\n",
       " 'California•Remote',\n",
       " 'Santa Monica, CA',\n",
       " 'San Francisco, CA',\n",
       " 'Orange County, CA',\n",
       " 'Santa Monica, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Santa Monica, CA•Remote',\n",
       " 'Los Angeles, CA 90016',\n",
       " 'California+1 location•Remote',\n",
       " 'California•Remote',\n",
       " 'Mountain View, CA',\n",
       " 'Santa Monica, CA•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'San Francisco, CA (North Waterfront area)',\n",
       " 'Burbank, CA',\n",
       " 'California•Remote',\n",
       " 'San Jose, CA',\n",
       " 'Santa Clara, CA 95054',\n",
       " 'San Francisco, CA',\n",
       " 'El Segundo, CA 90245',\n",
       " 'San Mateo, CA',\n",
       " 'San Francisco, CA',\n",
       " 'Carlsbad, CA 92008',\n",
       " 'Santa Monica, CA',\n",
       " 'South San Francisco, CA 94080',\n",
       " 'Fremont, CA',\n",
       " 'San Francisco, CA (North Waterfront area)',\n",
       " 'San Diego, CA 92127 (Rancho Bernardo area)',\n",
       " 'California•Remote',\n",
       " 'San Francisco, CA 94016+2 locations•Remote',\n",
       " 'Santa Clara, CA',\n",
       " 'California•Remote',\n",
       " 'Palo Alto, CA•Remote',\n",
       " 'California•Remote',\n",
       " 'Pleasanton, CA',\n",
       " 'Alamo, CA',\n",
       " 'Santa Monica, CA',\n",
       " 'Carlsbad, CA 92008',\n",
       " 'California•Remote',\n",
       " 'San Francisco, CA 94133 (Russian Hill area)',\n",
       " 'Los Angeles, CA',\n",
       " 'San Francisco, CA',\n",
       " 'Mountain View, CA',\n",
       " 'San Mateo, CA',\n",
       " 'Santa Monica, CA 90404',\n",
       " 'Redwood City, CA',\n",
       " 'California+1 location•Remote',\n",
       " 'Carlsbad, CA 92008',\n",
       " 'Pleasanton, CA 94566',\n",
       " 'Palo Alto, CA 94303',\n",
       " 'San Francisco, CA 94105 (South Beach area)',\n",
       " 'California',\n",
       " 'Santa Monica, CA•Remote',\n",
       " 'Montebello, CA 90640•Remote',\n",
       " 'San Francisco, CA 94107 (Yerba Buena area)',\n",
       " 'Santa Monica, CA•Remote',\n",
       " 'San Francisco, CA 94016+2 locations•Remote',\n",
       " 'San Diego, CA 92128 (Rancho Bernardo area)•Remote',\n",
       " 'Palo Alto, CA 94301 (Downtown North area)+1 location',\n",
       " 'Redwood City, CA',\n",
       " 'California•Remote',\n",
       " 'California•Remote',\n",
       " 'Los Angeles, CA',\n",
       " 'San Francisco, CA',\n",
       " 'Los Angeles, CA',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Mountain View, CA',\n",
       " 'Carlsbad, CA',\n",
       " 'Alamo, CA',\n",
       " 'Palo Alto, CA',\n",
       " 'San Francisco, CA',\n",
       " 'Fremont, CA 94555 (Ardenwood area)',\n",
       " 'Menlo Park, CA 94025+4 locations',\n",
       " 'Woodland Hills, CA 91367',\n",
       " 'Pleasanton, CA',\n",
       " 'California•Remote',\n",
       " 'Santa Barbara, CA',\n",
       " 'California•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco, CA+1 location•Remote',\n",
       " 'Foster City, CA',\n",
       " 'California',\n",
       " 'Long Beach, CA 90808 (Airport Area area)',\n",
       " 'California',\n",
       " 'San Francisco, CA+1 location•Remote',\n",
       " 'San Mateo, CA',\n",
       " 'California•Remote',\n",
       " 'Pleasanton, CA',\n",
       " 'San Francisco, CA 94107 (South Of Market area)',\n",
       " 'Los Altos, CA 94022•Remote',\n",
       " 'Palo Alto, CA•Remote',\n",
       " 'Santa Monica, CA 90404',\n",
       " 'California•Remote',\n",
       " 'Redwood City, CA',\n",
       " 'California•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'California•Remote',\n",
       " 'San Mateo, CA•Remote',\n",
       " 'Mountain View, CA',\n",
       " 'Newport Beach, CA',\n",
       " 'Carlsbad, CA',\n",
       " 'San Diego, CA 92122 (University City area)',\n",
       " 'Santa Clara, CA 95054',\n",
       " 'California•Remote',\n",
       " 'Foster City, CA',\n",
       " 'Sunnyvale, CA 94085+20 locations•Remote',\n",
       " 'Pleasanton, CA',\n",
       " 'Newport Beach, CA',\n",
       " 'Burbank, CA 91505+1 location',\n",
       " 'Santa Monica, CA 90404',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Folsom, CA 95630',\n",
       " 'Mountain View, CA',\n",
       " 'San Francisco, CA',\n",
       " 'San Mateo, CA',\n",
       " 'Milpitas, CA 95035•Remote',\n",
       " 'Fremont, CA 94555 (Northgate area)',\n",
       " 'Los Angeles, CA•Remote',\n",
       " 'San Francisco, CA 94104 (Financial District area)',\n",
       " 'San Francisco, CA 94107 (South Of Market area)',\n",
       " 'San Francisco, CA',\n",
       " 'Fremont, CA',\n",
       " 'Woodland Hills, CA 91367',\n",
       " 'Vernon, CA',\n",
       " 'Carlsbad, CA•Temporarily Remote',\n",
       " 'San Francisco, CA',\n",
       " 'Santa Monica, CA 90404',\n",
       " 'Mountain View, CA',\n",
       " 'California•Remote',\n",
       " 'California•Remote',\n",
       " 'San Francisco, CA 94103 (South of Market area)',\n",
       " 'San Jose, CA 95134 (North San Jose area)',\n",
       " 'Costa Mesa, CA 92626•Remote',\n",
       " 'Fremont, CA 94555 (Northgate area)',\n",
       " 'Santa Monica, CA 90404',\n",
       " 'Menlo Park, CA',\n",
       " 'California•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'Santa Monica, CA 90401 (Downtown/Third Street Promenade area)',\n",
       " 'San Francisco, CA 94103 (South of Market area)',\n",
       " 'Pleasanton, CA',\n",
       " 'Irvine, CA 92618•Temporarily Remote',\n",
       " 'Los Angeles, CA 90013 (Downtown area)+2 locations',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Fremont, CA',\n",
       " 'Oakland, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Redwood City, CA 94063',\n",
       " 'El Segundo, CA 90245',\n",
       " 'California•Remote',\n",
       " 'San Mateo, CA 94402 (Aragon area)',\n",
       " 'Los Gatos, CA',\n",
       " 'Fremont, CA',\n",
       " 'Santa Clara, CA',\n",
       " 'Carlsbad, CA•Temporarily Remote',\n",
       " 'Menlo Park, CA 94025+4 locations',\n",
       " 'Irvine, CA 92603•Remote',\n",
       " 'California•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco, CA 94016+2 locations',\n",
       " 'San Francisco, CA',\n",
       " 'Pleasanton, CA 94566',\n",
       " 'California•Remote',\n",
       " 'Menlo Park, CA 94025',\n",
       " 'San Francisco, CA+1 location',\n",
       " 'San Francisco, CA',\n",
       " 'Costa Mesa, CA 92626•Remote',\n",
       " 'Palo Alto, CA',\n",
       " 'Menlo Park, CA 94025',\n",
       " 'California•Remote',\n",
       " 'Los Angeles, CA 90291 (Venice area)',\n",
       " 'Redwood City, CA',\n",
       " 'San Jose, CA 95113 (Downtown area)',\n",
       " 'Long Beach, CA 90808 (Airport Area area)',\n",
       " 'San Diego, CA',\n",
       " 'San Francisco, CA 94105 (South Beach area)',\n",
       " 'Palo Alto, CA',\n",
       " 'San Francisco, CA',\n",
       " 'Los Angeles, CA',\n",
       " 'San Francisco, CA+1 location•Remote',\n",
       " 'San Jose, CA 95126 (Downtown area)',\n",
       " 'San Francisco, CA',\n",
       " 'Los Angeles, CA+4 locations•Remote',\n",
       " 'Foster City, CA',\n",
       " 'San Francisco, CA',\n",
       " 'Folsom, CA 95630',\n",
       " 'San Jose, CA 95131 (North San Jose area)',\n",
       " 'Los Angeles, CA',\n",
       " 'San Carlos, CA 94070',\n",
       " 'Culver City, CA',\n",
       " 'San Francisco, CA 94108 (Financial District area)',\n",
       " 'Menlo Park, CA 94025',\n",
       " 'Mountain View, CA 94035',\n",
       " 'San Carlos, CA 94070',\n",
       " 'Redwood City, CA 94065 (Westport area)',\n",
       " 'Palo Alto, CA 94303',\n",
       " 'Redwood City, CA 94063+1 location',\n",
       " 'San Francisco, CA 94107 (South Beach area)+1 location',\n",
       " 'San Francisco, CA',\n",
       " 'Santa Monica, CA 90401 (Downtown/Third Street Promenade area)',\n",
       " 'Foster City, CA',\n",
       " 'California•Remote',\n",
       " 'Sunnyvale, CA',\n",
       " 'Mountain View, CA',\n",
       " 'California•Remote',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'San Mateo, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Northridge, CA 91325',\n",
       " 'Milpitas, CA•Temporarily Remote',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco, CA',\n",
       " 'Redwood City, CA',\n",
       " 'Santa Monica, CA 90404',\n",
       " 'San Francisco, CA',\n",
       " 'Los Angeles, CA•Temporarily Remote',\n",
       " 'Santa Monica, CA',\n",
       " 'Redwood City, CA 94063+1 location',\n",
       " 'Fremont, CA',\n",
       " 'San Francisco, CA',\n",
       " 'Santa Clara, CA 95054',\n",
       " 'Palo Alto, CA',\n",
       " 'California•Remote',\n",
       " 'Palo Alto, CA',\n",
       " 'Los Angeles, CA',\n",
       " 'Menlo Park, CA 94025',\n",
       " 'Los Angeles, CA',\n",
       " 'Chico, CA',\n",
       " 'Los Angeles, CA 90069',\n",
       " 'San Jose, CA 95134 (North San Jose area)•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'Mountain View, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'Santa Clara, CA 95054',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'San Carlos, CA 94070',\n",
       " 'San Mateo, CA',\n",
       " 'Hollywood, CA•Temporarily Remote',\n",
       " 'San Diego, CA',\n",
       " 'El Segundo, CA•Remote',\n",
       " 'Chatsworth, CA 91311',\n",
       " 'Foster City, CA',\n",
       " 'Burbank, CA',\n",
       " 'San Francisco, CA',\n",
       " 'Milpitas, CA•Temporarily Remote',\n",
       " 'Sunnyvale, CA 94085 (East Murphy area)',\n",
       " 'Redwood City, CA',\n",
       " 'Sunnyvale, CA 94086 (East Murphy area)•Remote',\n",
       " 'Los Angeles, CA',\n",
       " 'Santa Ana, CA 92707',\n",
       " 'Palo Alto, CA',\n",
       " 'Los Angeles, CA•Remote',\n",
       " 'San Diego, CA',\n",
       " 'Santa Clara, CA 95054',\n",
       " 'California',\n",
       " 'San Francisco, CA',\n",
       " 'San Mateo, CA',\n",
       " 'California•Remote',\n",
       " 'Pleasanton, CA',\n",
       " 'San Francisco, CA+1 location•Remote',\n",
       " 'Long Beach, CA 90808 (Airport Area area)',\n",
       " 'Carlsbad, CA•Temporarily Remote',\n",
       " 'Chatsworth, CA 91311',\n",
       " 'California•Remote',\n",
       " 'Santa Clara, CA 95054',\n",
       " 'Montebello, CA 90640•Remote',\n",
       " 'California•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'Irvine, CA 92618 (Irvine Health and Science Complex area)•Temporarily Remote',\n",
       " 'San Mateo, CA 94402 (Aragon area)',\n",
       " 'San Francisco, CA',\n",
       " 'Sunnyvale, CA 94085 (East Murphy area)',\n",
       " 'Pleasanton, CA',\n",
       " 'Menlo Park, CA 94025•Remote',\n",
       " 'Palo Alto, CA',\n",
       " 'Menlo Park, CA',\n",
       " 'San Francisco, CA+1 location',\n",
       " 'Palo Alto, CA 94303',\n",
       " 'Mountain View, CA 94035',\n",
       " 'Sunnyvale, CA 94043',\n",
       " 'San Francisco, CA 94103 (South of Market area)',\n",
       " 'Santa Monica, CA 90401 (Downtown/Third Street Promenade area)',\n",
       " 'Palo Alto, CA',\n",
       " 'Pleasanton, CA',\n",
       " 'California',\n",
       " 'San Francisco, CA',\n",
       " 'Los Gatos, CA',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'Los Angeles, CA•Remote',\n",
       " 'Los Angeles, CA•Remote',\n",
       " 'Folsom, CA 95630',\n",
       " 'Santa Clara, CA 95054',\n",
       " 'Palo Alto, CA 94303',\n",
       " 'Menlo Park, CA 94025•Remote',\n",
       " 'California•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'California•Remote',\n",
       " 'Carlsbad, CA 92008+1 location',\n",
       " 'San Jose, CA 95002 (North San Jose area)',\n",
       " 'California•Remote',\n",
       " 'Lathrop, CA',\n",
       " 'San Francisco, CA 94104 (Financial District area)',\n",
       " 'San Francisco, CA',\n",
       " 'Sunnyvale, CA 94043',\n",
       " 'Culver City, CA',\n",
       " 'San Francisco, CA 94103 (South of Market area)',\n",
       " 'Menlo Park, CA',\n",
       " 'California•Remote',\n",
       " 'Folsom, CA 95630',\n",
       " 'San Diego, CA 92101•Remote',\n",
       " 'Los Angeles, CA',\n",
       " 'Los Angeles, CA•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco, CA 94105 (South Beach area)',\n",
       " 'Mountain View, CA',\n",
       " 'California•Remote',\n",
       " 'Redwood City, CA',\n",
       " 'San Francisco, CA',\n",
       " 'San Mateo, CA',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco, CA 94103 (South of Market area)',\n",
       " 'San Jose, CA 95134 (North San Jose area)',\n",
       " 'Milpitas, CA•Remote',\n",
       " 'San Francisco, CA•Remote',\n",
       " 'California•Remote',\n",
       " 'California+1 location•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'Santa Clara, CA 95054+2 locations',\n",
       " 'Menlo Park, CA',\n",
       " 'San Francisco, CA',\n",
       " 'San Jose, CA 95134 (North San Jose area)',\n",
       " 'Fremont, CA 94555 (Northgate area)',\n",
       " 'San Francisco, CA',\n",
       " 'Fremont, CA']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Proven proficiency with scripting languages such as Python, Ruby, and JavaScript, and build tools such as Jenkins, Maven, Ant, Gradle or Ivy.',\n",
       " 'Experience with ETL processes, extracting data.\\nBuilding key data sets to empower operational and exploratory analysis.',\n",
       " 'Using programming skills to create data pipelines, that can deal with both structured and unstructured data.\\nIf you are passionate about data or are keen to get…',\n",
       " 'Proficient with data management and integration, data engineering concept, design and development.\\nAbility to perform data tasks using a variety of SQL, and…',\n",
       " 'Understand and implement data logging best practices to support our data flow.\\nPartner closely with data scientists, business Intelligence analysts and machine…',\n",
       " 'Understand various business needs and requirements for a consistent and flexible set of data rules and standards.',\n",
       " 'Developing data infrastructure that ingest & transforms data from different sources, securely and at scale.\\nLeverage API & Microservices architecture for Data…',\n",
       " 'Create data pipeline monitoring automation.\\nAn understanding of leveraging data storage in Amazon S3.\\nDevelop integrations with external resources (sFTP, API’s,…',\n",
       " 'Experience defining and rationalizing complex data models within data warehousing environment.\\nKnowledge of data warehousing and information management best…',\n",
       " 'You will transform data from data warehouse tables into impactful membership growth initiatives.\\nYou will sit at the intersection of data engineering and data…',\n",
       " 'Troubleshoot emergent customer data pipeline issues.\\nUnderstand the evolving needs of the customer-facing product and data science teams, and how these will be…',\n",
       " 'Demonstrated ability to analyze large data sets to identify gaps and inconsistencies, provide data insights and advance effective product solutions.',\n",
       " 'Major skills required: Tableau, ETL, Informatica and GCP.\\nSkills: All GCP core services, Python, SQL, Big query, Data Warehousing, Data Modelling, ETL, Oracle…',\n",
       " 'Experience with extracting and aggregating data from large data sets using SQL or other tools.\\nCommunicate with clients to understand the challenges they face…',\n",
       " 'Looking for those network/data center engineers that like blinky lights.\\nProvide onsite network support and expertise for all teams on the local data center,…',\n",
       " 'Experience with extracting and aggregating data from large data sets using SQL or other tools.\\nCommunicate with clients to understand the challenges they face…',\n",
       " 'Looking for those network/data center engineers that like blinky lights.\\nProvide onsite network support and expertise for all teams on the local data center,…',\n",
       " 'Provides plan with data, reporting, and analyses that enable data-driven decision-making.\\nExperience with other relational databases, BI reporting and data…',\n",
       " 'Building out our data infrastructure and managing dependencies between data pipelines.\\nYou have 1-2 years of industry experience as a data engineer.',\n",
       " 'We work to streamline data access through light, agile data infrastructure, improving data management and governance, boosting capacity to use data through…',\n",
       " 'Experience designing data models and data warehouses and with non-relational data storage systems (NoSQL and distributed database management systems).',\n",
       " '\\\\*3+ years’ experience working as an engineer in a data focused team developing data processing frameworks and capabilities.\\nJob Types: Full-time, Contract.',\n",
       " 'Works with a variety of datasets, including timeseries data and “big data” requiring analysis on distributed computing platforms.',\n",
       " 'Build deep HR data expertise and own data quality for allocated areas of ownership.\\nIdentify, investigate and solve data quality issues and make sure the data…',\n",
       " 'Ensure ongoing data quality and manage data governance that enables rapid adoption- Support the creation and facilitation of data engineering education programs…',\n",
       " 'Build high-performance data pipelines and prototypes that enable business use of the data.\\nExperience in data engineering, 1 years.',\n",
       " 'Develop data set processes and projects requirements, and use large data sets to resolve major business and functional issues while improving data reliability,…',\n",
       " 'Expertise in AWS data processing services is required.\\nBuilding and managing data pipelines, databases and large-scale processing systems.',\n",
       " 'Integrate third-party data sources with our data infrastructure.\\nYou have 3+ years or experience and are capable of working as the sole data & machine learning…',\n",
       " 'Develop custom data models and algorithms to apply to data sets.\\nExtracting and aggregating data from large data sets using SQL/Hive or Spark.',\n",
       " 'Prior experience in performing and documenting data analysis, data validation, and data mapping/design.\\nProven experience of working as a data scientist, or in…',\n",
       " 'Experience with data modeling, data warehousing, and building ETL pipelines.\\nExperience working in very large data warehousing environments.',\n",
       " 'Defining processes for data monitoring as well as maintaining data integrity in our data ecosystem.\\nTechnical support of data analytics operation.',\n",
       " 'Alerts senior engineers of off-nominal data.\\nThis role will perform data analysis of flight test data.\\nWork experience with 1553 data products.',\n",
       " 'Experience building and maintaining a data warehouse in production.\\nExperience with data transformation tools like Spark or Hadoop.',\n",
       " 'Design and delivery of scalable data-driven applications in real-time platforms.\\nAssist in analyzing diverse sets of imperfect data and finding common patterns,…',\n",
       " 'Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights visually in a meaningful way.',\n",
       " 'You have experience working with large, complex data sets (preferably retail industry data or something relevant) for 3-5 years.',\n",
       " 'Familiarity with best practices for data visualization.\\n5+ years of hands-on data experience.\\nAn ideal candidate will have hands-on experience working with ETL…',\n",
       " 'Strong background in data modeling, data access, and data storage techniques.\\nCollaborate with internal and external data providers on data validation providing…',\n",
       " '5+ years of experience in data engineering.\\nStrong background in data warehouse concept and design.\\nHire Type: *Permanent / Full Time OR Contract (6 Months+).',\n",
       " 'Experience analyzing and collecting data as our data needs grow.\\nWe have MySQL databases for our production OLTP systems and our data lake/data warehouse built…',\n",
       " 'Have extensive knowledge building data pipelines and infrastructure that can adapt and scale as data volume grows and customer needs evolve.',\n",
       " 'Strong experience and understanding of very largescale data architecture, solutioning and operationalization of data warehouses, data lakes and analytics…',\n",
       " 'Develop complex data processing pipelines from multiple data sources.\\n4+ years data engineering experience.\\nLead the design of our data infrastructure.',\n",
       " 'Experience leading a small team of data or software engineers.\\nDevelop data pipelines adhering with privacy and governance principles.',\n",
       " 'The primary responsibilities will be in building, managing and optimizing data pipelines and then moving these data pipelines effectively into production for…',\n",
       " 'Experience in performing data analysis, data ingestion and ETL(Extraction, Transformation & Loading).\\nEstablish solid design and best engineering practice for…',\n",
       " 'Data modeling and data pipeline development.\\nData modeling and data pipeline development: 8 years (Required).\\nMust sit in California or Seattle, WA (no remote).',\n",
       " '6、Collaborate team members (e.g., data architects, data scientists) on the project’s goals.\\n3、Recommend different ways to constantly improve data reliability…',\n",
       " 'You will design, build, and maintain Rubrik’s cloud data protection services.\\nExperience in data structures, algorithms, software design, and systems analysis.',\n",
       " 'Analyze structural requirements for data storage solutions and software.\\nData Engineers are focused on enabling a data driven approach to optimization by…',\n",
       " 'Experience in implementing data pipelines using python.\\nWork with team members to assist with data-related technical issues and support their data product needs…',\n",
       " 'Our mission is to make reliable data available and enable value creation by the data community of engineers, analysts and decision makers.',\n",
       " 'This includes data collection, and outbound data transfer.\\nExperience with data/workflow engines a plus.\\nExcellent understanding of distributed data streaming…',\n",
       " 'As a part of the Data Platform team, you will be working across a wide range of problems in the data ingestion, data compute, data transport, data orchestration…',\n",
       " 'Wurl is seeking a detail-oriented data scientist/engineer with strong analytical and communication skills to join and grow with our data analytics team.',\n",
       " 'Build and maintain the infrastructure and data pipelines required for optimal extraction, transformation, and loading of data from a wide variety of data…',\n",
       " 'Create Enterprise-class reports and visualizations into the data.\\nProvide your expertise in understanding how data can be consumed across services.',\n",
       " 'Our competitive edge comes from making decisions based on accurate and timely data.\\nYou should be comfortable building complex yet performant SQL queries on…',\n",
       " '1+ years in a data engineering role.\\nExperience with building stream and batch data processing systems.\\nCollaborate with Integration team to build ETL processes…',\n",
       " 'Knowledge in scaling data-driven systems.\\nExperience architecting data infrastructure for machine learning applications.\\nFlexible time off & paid holidays.',\n",
       " 'Experience in optimizing data pipeline architecture, maintaining data flows, and ensuring consistent data collection for cross functional teams.',\n",
       " 'Detect data quality issues, identify their root causes, implement fixes, and design data audits to capture issues.\\nExperience with Amazon SageMaker is a plus.',\n",
       " 'Data governance – experienced in developing and integrating software allowing for flexible and scalable data transformation with data quality controls.',\n",
       " 'Deep understanding of data pipelines and data transformation.\\nWork with the lead engineer and engineering manager to understand the data lake and ETL…',\n",
       " 'Make data model and ETL code improvements to improve pipeline efficiency and data quality.\\nAnalyze new data sources and work with stakeholders to understand the…',\n",
       " '4+ years of experience as data platform engineer.\\nBuild data lake and implement data cataloging platform for easy data discovery and availability.',\n",
       " 'We have quite a few open positions with our direct clients in West Coast Area, USA with least or no competition.\\nType: Citizens, GC,H1B, H4, OPT.',\n",
       " 'An ability to provide technical guidance, direction and problem solving to data engineering team members.\\n8+ years of experience as a Data Warehouse Analyst,…',\n",
       " 'Work with service engineers and firmware engineers to understand what features could help predict issues.\\nSchedule and operate your model in a production data…',\n",
       " 'Experience defining and rationalizing complex data models within data warehousing environment.\\nKnowledge of data warehousing and information management best…',\n",
       " 'Should have working experience of using Spark data frame and data sets.\\n_\\\\*Candidates must be authorized to work in the U.S. We are unable to sponsor work visas…',\n",
       " 'Demonstrated ability to analyze large data sets to identify gaps and inconsistencies, provide data insights, and advance effective product solutions.',\n",
       " '3-5 years’ experience with data engineering using Python based data pipelines.\\n3-5 years’ experience in loading source system data extracts into data warehouse.',\n",
       " 'Design and implement scalable and reliable data models for our data.\\nDesign and build efficient data pipelines to move data across systems – SQL, NoSQL, GCP.',\n",
       " 'Assist with conducting data design, API design and application component architecture.\\nExperience with RDBS and NoSQL Databases such as Postgres, MySQL, Mongo,…',\n",
       " 'Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights…',\n",
       " '3+ years of experience as a data engineer.\\nHelp shape the growth of in-house data resources to support business Intelligence, analytics, and data science.',\n",
       " '2+ years of hands on experience with data core modernization and data ingestion.\\nImplement large-scale data ecosystems including data management, governance and…',\n",
       " 'Skills of transforming data, developing data structures, building a metadata store, setting up data pipelines or data workflows.\\nPassion of big data platform.',\n",
       " 'Interface with internal data science, engineering and data consumer teams to understand the data needs.\\nWe are looking for a passionate big data engineer who…',\n",
       " 'Experience with visualizing data (e.g. data dashboards).\\nYou will work in a small team of data science and algorithm engineers to expand our internal and…',\n",
       " 'Proficiency in all facets of DW Architecture, data flow strategy, data modeling, metadata and master data management.',\n",
       " 'Build data ingestion engine, data processing using Python, synchronizing data between up and down stream systems; AWS and GCS.',\n",
       " 'Reason and communicate in result-oriented, data-driven manner.\\nProtect TikTok users, including and beyond content consumers, creators, advertisers;',\n",
       " 'Experience developing data pipelines and logical data models within cloud data warehouses.\\nGather and understand data requirements, build complex data pipelines…',\n",
       " 'Knowledge of data management fundamentals and data storage principles.\\nInterface with other technology teams to extract, transform, and load data from a wide…',\n",
       " 'This expert engineer will be expected to have both deep technical skills in data architecture and big data, as well as leadership and organizational skills.',\n",
       " 'Democratize data access amongst engineers, PMs, and scientists with well-documented and extensible pipelines and datasets.\\nExperience with Airflow and Druid.',\n",
       " 'Democratize data access amongst engineers, PMs, and scientists with well-documented and extensible pipelines and datasets.\\nExperience with Airflow and Druid.',\n",
       " 'Deep understanding of key algorithms and tools for developing high efficiency data processing systems.\\nPartner with Machine Learning engineers and develop our…',\n",
       " 'Perform data quality validations to ensure data creation.\\nAcquire data from primary or secondary data sources and maintain databases/data systems to empower…',\n",
       " 'Looking for AWS Data engineer.\\nExperienced in using various AWS services related to Data.\\nJob Types: Full-time, Contract.',\n",
       " 'Experience working with regulated data such as medical or financial data.\\nAssist in building web-based data labeling tools with optimized UI/UX to enable…',\n",
       " 'Demonstrated experience resolving complex data integration problems;\\n4+ years working experience in data integration and pipeline development.',\n",
       " 'Big data: 3 years (Required).\\n3+ years of experience in working with big data and related technologies.\\nLatentView Analytics is a leading global analytics and…',\n",
       " 'Experience with performing data analysis, data ingestion and data integration;\\nExperience with schema design, data modeling and SQL queries;',\n",
       " 'Utilized gathered data to generate tasks that can be automated to keep track of data/models/requirement changes.\\nDevelopment of data related/instruments.',\n",
       " 'Develop protocols and manage the data governance process to promote data standards, data quality & data security.\\nBenefits: medical, dental, vision, 401k.',\n",
       " 'Write new data pipeline jobs to retrieve and validate training data.\\nThis team provides data pipelines and data APIs to data scientists so they can make our…',\n",
       " 'Experience working with event data in a data lake.\\nA self-service tool that allows data scientists, data engineers, and ML engineers on the Marketing Data…',\n",
       " 'Define data validation tests to run in the data pipeline.\\nYou and the team are responsible for building, deploying, maintaining, and optimizing the data…',\n",
       " 'You will design and build highly scalable and reliable modern data platforms including data lakes and data warehouse using Amazon Web Services, Azure, Google…',\n",
       " 'You will have opportunities to recommend and assist in data acquisition, data quality and reliability improvements and other areas to improve not only the data…',\n",
       " 'Working with internal product teams to ingest their data and sprinkle machine/deep learning fairy dust on their products.',\n",
       " 'This includes Student Information System data (SIMSR and Peoplesoft Campus Solutions), survey data, campus, and external data.',\n",
       " '1 year SQL, Python, Apache Airflow, pipeline creation, maintenance, data visualization.\\nAccenture Flex employees work in their local metro area onsite at the…',\n",
       " 'You’ve got a solid foundation: This role requires both a broad and deep understanding of data; you must have an advanced understanding of MPP databases, data…',\n",
       " 'As a data engineer, you will design, build and maintain Happiest Baby’s data lake.\\nWork with data scientists and engineers to set up infrastructure to deploy AI…',\n",
       " '3+ years of experience in data warehouse and data migration.\\nDemonstrated knowledge of cloud infrastructure, data lineage, and data quality pipelines.',\n",
       " 'As a data Engineer, you will build from scratch highly available and highly scalable data processing systems using AWS technologies, Kafka, Map-Reduce, Hive and…',\n",
       " '\\\\* Owner of the core company data pipeline, responsible for scaling up data processing flow to meet the rapid data growth;\\n目前急招 Full-time.',\n",
       " 'Provides guidance and training to less experienced data architects.\\nDevelops, tests, and deploys data structures using Entity Relationship Diagramming, SQL…',\n",
       " 'Participate in data strategy and road map exercises, business intelligence/data warehouse product selection, design and implementation.',\n",
       " 'Being a data informed company, data helps us create exceptional experience for our customers and provide insights into the effectiveness of our product.',\n",
       " 'An ideal candidate will have extensive knowledge of the data warehouse architecture, capabilities, system setup, data integration, data modeling concepts.',\n",
       " 'Prior experience in data warehousing projects preferred.\\nExperience in architecting data structures using Elastic Search and ElastiCache.',\n",
       " 'Coach and mentor engineers across the engineering team to build a data culture.\\nYou have 5+ years of experience in engineering, especially data infrastructure…',\n",
       " 'Understanding of standard data quality metrics.\\nExperience with BI Analytics and Data ETL (Extraction, Transformation, and Loading) with large amounts of data.',\n",
       " 'Understanding of standard data quality metrics.\\nExperience with BI Analytics and Data ETL (Extraction, Transformation, and Loading) with large amounts of data.',\n",
       " 'Experience in data modeling, data warehousing and data visualization is a big plus.\\nData: Design, develop and maintain core databases that support the company…',\n",
       " 'Architect the data backbone for the Xwing fleet to advance the entire autonomy stack (perception, prediction, planning and controls).',\n",
       " 'Experience with integrations and data warehousing using tools like redshift.\\nStong, hands-on experience with Python-centric code base and Python best practices.',\n",
       " 'Work with data engineers and data scientists to drive efficient solutions from the platform.\\nHelp define the data story and enable data-driven solutions at…',\n",
       " 'Document and maintain data dictionary to empower a data democracy.\\nDevelop data tests for automation.\\nExperience in building data pipelines.',\n",
       " 'Manage and create insightful data visualizations and dashboards.\\nWork with internal teams to establish ETL and data cleansing processes.',\n",
       " 'Working with data scientists and digital teams to meet strategic data needs through project management tools like Microsoft Teams, JIRA, are desired.',\n",
       " 'Work closely with data experts to build and maintain KPI data dictionary, metadata, data standards, and ensure adherence to the Plans Analytics Method and data…',\n",
       " 'Collaborate with data analysts to bridge business goals with data delivery.\\nOversee systems tracking data quality and consistency.',\n",
       " 'Big data tools: Spark, etc.\\nWork with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support…',\n",
       " 'A passionate bias to action and passion for delivering high-quality data solutions.\\nThe Data Reliability Engineering team for Disney Streaming Services (DSS), a…',\n",
       " 'Experience building/operating systems for data extraction, ingestion and processing of large data sets.\\nBuild and maintain tools and infrastructure for data…',\n",
       " 'Training analysts and data scientists alike on available data sources.\\nThe Staff Data Engineer will also work closely with ServiceNow data analysts and data…',\n",
       " 'Relevant multi-year work or academic experience in data science or related fields such as data engineering, data analysis, software engineering, statistics, etc…',\n",
       " 'Prior experience in performing and documenting data analysis, data validation, and data mapping/design.\\nProven experience of working as a data scientist, or in…',\n",
       " 'You will build and guide processes to support efficient data transformation, data structures, metadata/data dictionaries, and workload management.',\n",
       " 'This role is responsible for focusing in retrieving, validating, processing and storing various data to guarantee the accessibility, reliability, and timeliness…',\n",
       " 'Strong experience and understanding of very largescale data architecture, solutioning and operationalization of data warehouses, data lakes and analytics…',\n",
       " 'As a part of the Data Platform team, you will be working across a wide range of problems in the data ingestion, data compute, data transport, data orchestration…',\n",
       " 'Experience building/operating systems for data extraction, ingestion and processing of large data sets.\\nBuild and maintain tools and infrastructure for data…',\n",
       " 'Design your full-time freelance career as a top freelance data engineer with Toptal.\\nPlus, Toptal takes care of all the overhead, empowering you to focus on…',\n",
       " 'Experience with ETL or large scale data processing.\\n1+ year or professional work experience as a software engineer or relevant internships.',\n",
       " 'Build and maintain the infrastructure and data pipelines required for optimal extraction, transformation, and loading of data from a wide variety of data…',\n",
       " '5 years professional software experience, including data warehousing, data integration, and ETL/analytics pipelines.\\nMust wear a mask when working onsite.',\n",
       " 'Lead the implementation of data standards and common data elements for data collection.\\nExpert ability to collect data using a variety of methods, such as data…',\n",
       " 'Identify and solve issues to improve data quality.\\nImprove data foundational procedures, guidelines and standards.\\nMedical, Dental, and Vision Coverage.',\n",
       " 'Interface with internal data science, engineering and data consumer teams to understand the data needs.\\nWe are looking for a passionate big data engineer who…',\n",
       " 'Experience defining and rationalizing complex data models within data warehousing environment.\\nKnowledge of data warehousing and information management best…',\n",
       " 'Demonstrated experience resolving complex data integration problems;\\nStrong prior technical, development background in either data Services or Engineering.',\n",
       " 'You should have deep expertise and passion in working with large data sets, data visualization, building complex data processes, performance tuning, bringing…',\n",
       " 'Guide our mechanical and electrical engineers to data nirvana.\\nBuild the tools and platforms for Mainspring engineers and data scientists to access, analyze,…',\n",
       " 'Utilized gathered data to generate tasks that can be automated to keep track of data/models/requirement changes.\\nDevelopment of data related/instruments.',\n",
       " 'Make sure quality of the data and data processes meet standards.\\nCreate new or modify existing data pipelines.\\nOwn and Be part of something big.',\n",
       " 'Experience with data pipelines processing larger than 10TB of data.\\nDevelop reliable data pipelines that convert data into powerful signals and features.',\n",
       " 'Experience with data modeling, data warehousing, KPI generation etc.\\nStrong knowledge of data pipeline and workflow management tools (Airflow).',\n",
       " 'Work with data and analytics experts to strive for greater functionality in the organization’s data integration platform.',\n",
       " 'Contribute to data pipelines that clean, transform and aggregate data from disparate data sources into reporting data stores.',\n",
       " 'Knowledge of healthcare data coding systems and common administrative data formats.\\nWorking with Data Analytics teams to support their data infrastructure needs…',\n",
       " 'Develop data center monitoring and control system designs and related hardware and software configurations (includes basis of design, constructability,…',\n",
       " 'Proficiency in all facets of DW Architecture, data flow strategy, data modeling, metadata and master data management.',\n",
       " 'Coach and mentor engineers across the engineering team to build a data culture.\\nYou have 5+ years of experience in engineering, especially data infrastructure…',\n",
       " 'This person will design and build data integrations, ETL workflows, dimensional data models, and manage our data warehouse and integration infrastructure that…',\n",
       " 'Design and delivery of scalable data-driven applications in real-time platforms.\\nAssist in analyzing diverse sets of imperfect data and finding common patterns,…',\n",
       " 'Familiarity with best practices for data visualization.\\n5+ years of hands-on data experience.\\nAn ideal candidate will have hands-on experience working with ETL…',\n",
       " 'Document and maintain data dictionary to empower a data democracy.\\nDevelop data tests for automation.\\nExperience in building data pipelines.',\n",
       " 'Train engineers in advanced manufacturing engineering methods and tools.\\nStandardize and document tools and methods for optimal manufacturing and assembly of…',\n",
       " '7+ years of data engineer experience in a successful data engineering or business intelligence team with expert knowledge of data warehouse architecture and…',\n",
       " 'We analyze data needed to provide actionable insights, draw conclusions from the data and support data driven decision making at Light.',\n",
       " 'Experience with performing data analysis, data ingestion and data integration;\\nExperience with schema design, data modeling and SQL queries;',\n",
       " 'Wurl is seeking a detail-oriented data scientist/engineer with strong analytical and communication skills to join and grow with our data analytics team.',\n",
       " 'Knowledge of data management tools and statistical process controls is required.\\nLead critical investigations, identify root causes and implement data-driven…',\n",
       " 'Define best data driven practices.\\nImplement and maintain data processing code.\\nCommercial experience with managing data infrastructure.',\n",
       " 'Our field sales professionals rely on proactive technical support during the sales process – and our expert Systems Engineering team always steps up to the mark…',\n",
       " 'Collaborate with data operations and analysts to ensure correct data sources and dataset development.\\nParticipate in application validation and QA efforts as…',\n",
       " 'Experience with integrations and data warehousing using tools like redshift.\\nStong, hands-on experience with Python-centric code base and Python best practices.',\n",
       " 'Work in setting up a world class data platform to enable highly personalized experiences for our members, while getting data to stakeholders, when, where and…',\n",
       " 'As a data engineer, you will design, build and maintain Happiest Baby’s data lake.\\nWork with data scientists and engineers to set up infrastructure to deploy AI…',\n",
       " '5+ years of professional experience as a data engineer or similar job functions.\\nYou will work with other data engineers and analytics engineers to shape the…',\n",
       " 'You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models.',\n",
       " '4+ years of experience as data platform engineer.\\nBuild data lake and implement data cataloging platform for easy data discovery and availability.',\n",
       " 'Work in setting up a world class data platform to enable highly personalized experiences for our members, while getting data to stakeholders, when, where and…',\n",
       " 'Experience with data pipelines processing larger than 10TB of data.\\nDevelop reliable data pipelines that convert data into powerful signals and features.',\n",
       " 'Experience with integrations and data warehousing using tools like redshift.\\nStong, hands-on experience with Python-centric code base and Python best practices.',\n",
       " 'Experience with data modeling, data warehousing, KPI generation etc.\\nStrong knowledge of data pipeline and workflow management tools (Airflow).',\n",
       " 'Work closely with data experts to build and maintain KPI data dictionary, metadata, data standards, and ensure adherence to the Plans Analytics Method and data…',\n",
       " 'This person will design and build data integrations, ETL workflows, dimensional data models, and manage our data warehouse and integration infrastructure that…',\n",
       " 'Deep understanding of key algorithms and tools for developing high efficiency data processing systems.\\nPartner with Machine Learning engineers and develop our…',\n",
       " 'Strong experience and understanding of very largescale data architecture, solutioning and operationalization of data warehouses, data lakes and analytics…',\n",
       " 'As our engineering team grows, we are looking for a data engineer working on geo data related data pipelines and data products.\\n3+ years as a software engineer.',\n",
       " 'Familiarity with best practices for data visualization.\\n5+ years of hands-on data experience.\\nAn ideal candidate will have hands-on experience working with ETL…',\n",
       " 'Build data pipelines to collect data from primary / secondary data sources and transform data within the warehouse.\\nParties, picnics, and Friday wine-downs.',\n",
       " 'Intimate experience working with Postgres database and other data stores with a preference for simple solutions to complex data storage needs.',\n",
       " 'Integrate multiple marketing data sources into customized data mart and design an efficient data architect to meet growing business demand.',\n",
       " 'Experience with ETL or large scale data processing.\\n1+ year or professional work experience as a software engineer or relevant internships.',\n",
       " 'Your problem-solving mindset will guide you in collaborating with domain experts, software engineers, and data engineers to create integrated solutions that…',\n",
       " 'Perform data quality validations to ensure data creation.\\nAcquire data from primary or secondary data sources and maintain databases/data systems to empower…',\n",
       " 'Experience with data modeling, data warehousing, KPI generation etc.\\nStrong knowledge of data pipeline and workflow management tools (Airflow).',\n",
       " 'Collaborates with peers, senior engineers, data scientists and project team.\\nUsing data engineering tools, languages, frameworks to cleanse, mine and explore…',\n",
       " 'The successful data engineer will leverage tools and build systems to deliver data to teams and applications.\\nExperience with streaming data pipelines is a plus…',\n",
       " 'Extracts data from various databases; perform exploratory data analysis, cleanses, massages, and aggregates data.\\nBig data processing techniques, preferred.',\n",
       " 'As a part of the Data Platform team, you will be working across a wide range of problems in the data ingestion, data compute, data transport, data orchestration…',\n",
       " 'You will work closely with executive stakeholders alongside machine learning engineers and data scientists to apply sophisticated modeling techniques on a…',\n",
       " 'Past experience maintaining data repositories with disparate data sources.\\nCreate and maintain a data repository for analytics by combining multiple data…',\n",
       " 'This person will design and build data integrations, ETL workflows, dimensional data models, and manage our data warehouse and integration infrastructure that…',\n",
       " 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow.\\nExperience with big data tools: Hadoop, Spark, Kafka, etc.',\n",
       " 'Experience architecting data warehouses and data lakes that are organized, performant, and easy to use.\\nThe Senior Data Engineer determines and identifies high…',\n",
       " 'Knowledge of data management tools and statistical process controls is required.\\nLead critical investigations, identify root causes and implement data-driven…',\n",
       " 'Design, implement, and support ETL data pipelines in a big data environment.\\nArchitect and design next generation data platform with appropriate new…',\n",
       " 'The data team is made up of 8 data engineers, analysts, and scientists.\\nWe work cross-functionally and fullstack delivering data pipelines, scripting automation…',\n",
       " 'Experience in data engineering, data warehousing, and ETL pipelines.\\n4 - 8 years of data engineering, data warehousing, and ETL pipelines experience.',\n",
       " 'Demonstrated grasp of relational data modeling techniques.\\nFive (5)+ years’ experience with: Oracle Database Interaction, Python Scripting/Development, API use…',\n",
       " '7+ years of data engineer experience in a successful data engineering or business intelligence team with expert knowledge of data warehouse architecture and…',\n",
       " 'Design and implement systems under trillion level data environment;\\nWork with product managers to define and develop big data applications;',\n",
       " 'You will collaborate closely with data-scientists, other ML Engineers, Software engineers, PMs, cross functional business units to address challenging problems…',\n",
       " 'A passionate bias to action and passion for delivering high-quality data solutions.\\nThe Data Reliability Engineering team for Disney Streaming (Disney+, Hulu,…',\n",
       " 'We analyze data needed to provide actionable insights, draw conclusions from the data and support data driven decision making at Light.',\n",
       " '5+ years of professional experience as a data engineer or similar job functions.\\nYou will work with other data engineers and analytics engineers to shape the…',\n",
       " 'Design, implement, and support ETL data pipelines in a big data environment.\\nArchitect and design next generation data platform with appropriate new…',\n",
       " 'Partner with data scientists and business stakeholders to understand data needs and help build data products that scale across the company.',\n",
       " 'Partner with our client’s leadership teams, engineers, program managers and data analysts to understand data needs.\\nExperience with data quality and validation.',\n",
       " 'They use their deep technical expertise to design the right data models and reliably turn these models into high-quality core data assets in our data warehouse.',\n",
       " 'Have experience in data modeling, schema design, and data warehousing.\\n5+ years of data engineering experience.\\nAmple paid time off to relax and recharge.',\n",
       " 'Work in setting up a world class data platform to enable highly personalized experiences for our members, while getting data to stakeholders, when, where and…',\n",
       " 'Proficiency in all facets of DW Architecture, data flow strategy, data modeling, metadata and master data management.',\n",
       " 'Design data models, data ingestion pipelines and implement scalable ETL / ELT processes.\\nThis role would contribute to the vision for data infrastructure and…',\n",
       " 'Work in setting up a world class data platform to enable highly personalized experiences for our members, while getting data to stakeholders, when, where and…',\n",
       " 'Extracts data from various databases; perform exploratory data analysis, cleanses, massages, and aggregates data.\\nBig data processing techniques, preferred.',\n",
       " 'Knowledge of healthcare data coding systems and common administrative data formats.\\nWorking with Data Analytics teams to support their data infrastructure needs…',\n",
       " 'Working with internal product teams to ingest their data and sprinkle machine/deep learning fairy dust on their products.',\n",
       " 'We analyze data needed to provide actionable insights, draw conclusions from the data and support data driven decision making at Light.',\n",
       " 'Architect and build data pipelines to extend and scale our data warehouse.\\nAlthough this position will be focused on data engineering, familiarity with other…',\n",
       " 'Develop ETL processes to merge data from disparate sources.\\nNinja-level data visualization and spreadsheet storytelling skills.\\n70%+ Pacific time-zone overlap.',\n",
       " 'You have experience building and maintaining ETLs, data pipelines, and data models.\\nStrong experience with distributed data architectures and big data…',\n",
       " 'Working with research coordinators, algorithm engineers, data scientists and research scientists to ensure that we are collecting high quality data in our…',\n",
       " 'Participate in data strategy and road map exercises, business intelligence/data warehouse product selection, design and implementation.',\n",
       " \"You've wrangled enough data to understand how often the complex systems that produce data can go wrong.\\nYou'll design and own mission-critical data pipelines to…\",\n",
       " 'Understanding of data science & machine learning use cases.\\nExperience building geospatial services and datasets, such as maps data.',\n",
       " 'Experience in performing data analysis, data ingestion and data integration.\\nParticipate in the security & compliance related projects as a data engineer.',\n",
       " 'These solutions include ETL, data modeling, data quality assessment and data delivery.\\nWork closely with product engineers and developers to fix data issues.',\n",
       " 'Experience architecting data warehouses and data lakes that are organized, performant, and easy to use.\\nThe Senior Data Engineer determines and identifies high…',\n",
       " 'Experience in working with large data sets.\\nExperience with Tableau for big data analytics.\\nExperience working with data center related electronics, packaging,…',\n",
       " 'Support the automation of data quality checks and seek to investigate and resolve related issues by debugging all aspects of the data pipeline and correcting…',\n",
       " 'Data modeling and data pipeline development.\\nData modeling and data pipeline development: 8 years (Required).\\nMust sit in California or Seattle, WA (no remote).',\n",
       " 'Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights visually in a meaningful way.',\n",
       " 'As a data Engineer, you will build from scratch highly available and highly scalable data processing systems using AWS technologies, Kafka, Map-Reduce, Hive and…',\n",
       " 'You will be working closely with the Security Operations, Network, Security, and IT teams in coordinating and automating data on-boarding in Splunk and in…',\n",
       " 'Strong understanding of relational data models.\\nDesigning and building intuitive relational and non-relational data models.\\nWriting and managing ETL processes.',\n",
       " 'Design and develop data pipelines to move data from source to target utilizing tools in BI toolbox.\\nStrong understanding of data visualization tools and…',\n",
       " 'Develop ETL processes to merge data from disparate sources.\\nNinja-level data visualization and spreadsheet storytelling skills.\\n70%+ Pacific time-zone overlap.',\n",
       " 'Architect the data backbone for the Xwing fleet to advance the entire autonomy stack (perception, prediction, planning and controls).',\n",
       " 'Experience with data security and privacy concerns, ideally with healthcare data.\\nFamiliarity with data governance frameworks.',\n",
       " 'Build and maintain a robust data engineering process to develop and implement self-serve data and tools for Visa’s data scientists.\\nGo lang and Scala is a plus.',\n",
       " 'Have experience in data modeling, schema design, and data warehousing.\\n5+ years of data engineering experience.\\nAmple paid time off to relax and recharge.',\n",
       " 'Create and maintain the data pipeline architecture for real-time data processing.\\nProficient at building processes supporting data transformation, data…',\n",
       " 'Have experience in data modeling, schema design, and data warehousing.\\n5+ years of data engineering experience.\\nAmple paid time off to relax and recharge.',\n",
       " 'Experience with data security and privacy concerns, ideally with healthcare data.\\nFamiliarity with data governance frameworks.',\n",
       " 'Build data pipelines to collect data from primary / secondary data sources and transform data within the warehouse.\\nParties, picnics, and Friday wine-downs.',\n",
       " 'The data team is made up of 8 data engineers, analysts, and scientists.\\nWe work cross-functionally and fullstack delivering data pipelines, scripting automation…',\n",
       " 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow.\\nExperience with big data tools: Hadoop, Spark, Kafka, etc.',\n",
       " 'The candidate will work on the data engineering part of product discovery models. search and recommendations.\\nScala and Java Experience a plus.',\n",
       " 'Experience with data analysis, data, munging and relative machine learning skills.\\nHireArt is helping Toyota Research Institute (TRI) find a Machine Learning…',\n",
       " 'Past experience maintaining data repositories with disparate data sources.\\nCreate and maintain a data repository for analytics by combining multiple data…',\n",
       " 'Proficiency in SQL, data modeling, and data warehousing.\\nCollaborate with product teams and data analysts to design and build data-forward solutions.',\n",
       " 'Recommended continuous improvements to our data governance practices and implemented data quality improvements.',\n",
       " 'We analyze data needed to provide actionable insights, draw conclusions from the data and support data driven decision making at Light.',\n",
       " \"You'll build and maintain a first-class data infrastructure that supports delivery of data.\\nYou have worked with ETL pipelines before and are familiar with…\",\n",
       " 'We provide tools to store, transform, move, and understand data.\\nTwitch is building the future of interactive entertainment.',\n",
       " 'Experience in doing technical landscape and data assessment in context of data transformation projects.\\nBuild Facts & dimensions schema for supply chain data.',\n",
       " 'The data replication engineering team focuses on the open-source project TiCDC (https://github.com/pingcap/ticdc) maintenance, new features development and…',\n",
       " 'Experience with performing data analysis, data ingestion and data integration.\\nExperience with schema design, data modeling and SQL queries.',\n",
       " 'Solve and help other team members solve complex data issues around data integration, unusable data elements, unstructured data sets, and other data processing…',\n",
       " 'Building infrastructure to automate data transformations and other data science processes.\\nExperience working with geospatial data and computer vision data (i.e…',\n",
       " 'Technical expertise in the areas of data profiling, data mining, and data analytics.\\nDefine, prepare, execute and implement data validation and unit testing…',\n",
       " 'Training analysts and data scientists alike on available data sources.\\nEnforcing company data policies and procedures to ensure data quality and reduce…',\n",
       " 'Experience in doing technical landscape and data assessment in context of data transformation projects.\\nBuild Facts & dimensions schema for supply chain data.',\n",
       " 'Big plus: Experience with distributed data processing system and data pipeline, including but not limited to Elasticsearch, Spark.',\n",
       " 'Working to supplement our current data providers to create an enriched data-set (unstructured data such as images, new data providers, integrations, etc.).',\n",
       " 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow.\\nExperience with big data tools: Hadoop, Spark, Kafka, etc.',\n",
       " 'Ensure robust data handling data of new and existing resources.\\nDefining goals for data management and strategizing how to use data resources most effectively.',\n",
       " 'Experience using Alation for catalogging data.\\nProactively monitor the data flows with a focus on continued performance improvements.',\n",
       " 'Proficiency in SQL, data modeling, and data warehousing.\\nCollaborate with product teams and data analysts to design and build data-forward solutions.',\n",
       " '3+ years experience developing ETL workflows as a data analytics engineer, data engineer, or data analyst.\\nExperience with data transformation tooling (dbt is…',\n",
       " \"The transaction will enhance the resources and potential of the business' storage solutions, including client and enterprise SSDs, in the rapidly growing NAND…\",\n",
       " 'Build data expertise and own data quality for allocated areas of ownership.\\nWork with product managers and data analysts to build data products that power our…',\n",
       " 'Architect the data backbone for the Xwing fleet to advance the entire autonomy stack (perception, prediction, planning and controls).',\n",
       " 'Build data pipelines to collect data from primary / secondary data sources and transform data within the warehouse.\\nParties, picnics, and Friday wine-downs.',\n",
       " 'Must have good knowledge of data modelling.\\nMust have good understanding to create complex data pipeline.\\nMust have worked on Batch and streaming data pipeline.',\n",
       " 'Develop simulation models and tools to monitor data center capacity performance and utilization: Monitoring, reporting, data-mining tools to do performance and…',\n",
       " 'Monitor our analytics data pipelines to ensure data quality and timeliness.\\nPartner closely with VP of Analytics to make data accessible to the entire company…',\n",
       " '1-3 years of experience in a data engineer, data architect, ETL analytics or similar role.\\nDevelop efficient queries to (1) extract data from data lakes and…',\n",
       " 'The candidate will work on the data engineering part of product discovery models. search and recommendations.\\nScala and Java Experience a plus.',\n",
       " 'Architectural and data schema design.\\nMust have delivered and supported production data warehouses.\\nHands on implementation of batch and streaming data and ETL…',\n",
       " 'Tesla is looking for a talented data engineer with experience working with the highly transactional and scalable data platform.',\n",
       " 'As a data Engineer, you will build from scratch highly available and highly scalable data processing systems using AWS technologies, Kafka, Map-Reduce, Hive and…',\n",
       " 'Experience developing data pipelines and logical data models within cloud data warehouses.\\nGather and understand data requirements, build complex data pipelines…',\n",
       " '1+ years of experience with ETL, data processing, and data analytics.\\nMaintain and develop data workflows, internal process improvements, and optimize data…',\n",
       " 'Evangelize high quality software engineering practices towards building data infrastructure and pipelines at scale.\\n5+ years of relevant experience.',\n",
       " 'Proficiency in SQL, data modeling, and data warehousing.\\nCollaborate with product teams and data analysts to design and build data-forward solutions.',\n",
       " 'Manage day-to-day operations of the Elasticsearch/Druid cluster, such as cluster administration, performance tuning and failure handling of cluster;',\n",
       " 'Build out our data platform including data storage, APIs, and pipelines.\\nDevelop new processes around data operations.\\nExperience with Ruby on Rails.',\n",
       " 'Strong knowledge of data technologies and data modeling.\\nDevelop core architecture of our data platform within GCP and advance data ingestion.',\n",
       " 'Demonstrated ability to analyze large data sets to identify gaps and inconsistencies, provide data insights, and advance effective product solutions.',\n",
       " 'Work with data and analytics experts to strive for greater functionality in the organization’s data integration platform.',\n",
       " 'Additionally, this person will read long complex SQL scripts, provide ETL solutions to optimize data delivery and build solutions that put data into tables.',\n",
       " 'Develop simulation models and tools to monitor data center capacity performance and utilization: Monitoring, reporting, data-mining tools to do performance and…',\n",
       " 'Proficiency in SQL, data modeling, and data warehousing.\\nCollaborate with product teams and data analysts to design and build data-forward solutions.',\n",
       " 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.\\nBuild the infrastructure required for optimal extraction,…',\n",
       " 'Mentor and guide junior data engineers.\\n5+ years of experience in building data lakes and data warehouses.\\nDocument, maintain and support data pipelines.',\n",
       " 'Help envision the next generation data platform by combining the data from our transaction systems with data from other data platforms to create unique data…',\n",
       " \"You'll contribute to a wide range of initiatives, flexing abilities from data science & data engineering, to backend systems & infrastructure engineering in…\",\n",
       " 'Own data reliability and help assess and determine which warehousing technologies to use, when to move data between data stores, and help productionize models.',\n",
       " 'Build scalable data pipelines for data mining and analytics.\\nExperience with ETL or large scale data processing.\\n3+ years experience working with Linux.',\n",
       " 'Engineers in GDW focus on data architecture, design, source data instrumentation, ETL pipeline optimization, and data model implementation.',\n",
       " 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow.\\nExperience with big data tools: Hadoop, Spark, Kafka, etc.',\n",
       " 'Experience with data warehousing concepts, such as normal forms, star and snowflake schemas and feel comfortable modeling complex data designs and…',\n",
       " '6+ years of experience in data engineering with an emphasis on data analytics and reporting.\\nBuild large-scale batch and real-time data pipelines with data…',\n",
       " \"You'll contribute to a wide range of initiatives, flexing abilities from data science & data engineering, to backend systems & infrastructure engineering in…\",\n",
       " 'Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.\\nThe ideal candidate is an experienced data pipeline builder and data…',\n",
       " 'Experience defining and rationalizing complex data models within data warehousing environment.\\nKnowledge of data warehousing and information management best…',\n",
       " 'Experience with integrations and data warehousing using tools like redshift.\\nEnjoys and is deeply comfortable with a Python-centric code base and Python best…',\n",
       " 'We are looking for a seasoned Staff level engineer to not only build data pipelines to efficiently and reliably move data across systems, but also to build the…',\n",
       " 'Familiarity with best practices for data visualization.\\n5+ years of hands-on data experience.\\nAn ideal candidate will have hands-on experience working with ETL…',\n",
       " 'Strong knowledge of data technologies and data modeling.\\nDevelop core architecture of our data platform within GCP and advance data ingestion.',\n",
       " 'You will utilize your knowledge of data structures and algorithms to develop highly performant features.\\nThe clean, intuitive, and beautiful user interface you…',\n",
       " 'We build and operate a flexible data gateway that facilitates data abstractions to operate at sub-millisecond latencies serving 10’s of millions of operations…',\n",
       " 'Tesla is looking for a talented data engineer with experience working with the highly transactional and scalable data platform.',\n",
       " 'Domain expertise in data analytics, e.g., ETL, ML, graph applications .\\nWork directly with key customers to perform in-depth analysis and optimization of…',\n",
       " '1+ years of experience with ETL, data processing, and data analytics.\\nMaintain and develop data workflows, internal process improvements, and optimize data…',\n",
       " 'Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights visually in a meaningful way.',\n",
       " \"You will work with large volumes of data, so if you have mastered data flow efficiency and optimization, we'd love to hear from you.\",\n",
       " 'Make sure quality of the data and data processes meet standards.\\nCreate new or modify existing data pipelines.\\nOwn and Be part of something big.',\n",
       " 'Have end-to-end ownership of projects throughout their lifecycle, supporting both engineers at Commure and third-party developers.',\n",
       " 'Comfortable working with very large data.\\nExperience with streaming data in Spark.\\nDesigning and developing a scalable data processing infrastructure.',\n",
       " 'Evangelize high quality software engineering practices towards building data infrastructure and pipelines at scale.\\n5+ years of relevant experience.',\n",
       " 'Partner with data scientists and business stakeholders to understand data needs and help build data products that scale across the company.',\n",
       " 'Establish, mentor and advice on data engineering best practices.\\nArchitect, Develop and maintain our data warehouse and analytics database.',\n",
       " 'Simple and scalable network design, automation, and data analytics are the keys to meeting our demands.\\nThis team owns the complete lifecycle of the Data Center…',\n",
       " 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.',\n",
       " 'You will collaborate with many teams across Square to understand data needs and turn those needs into data infrastructure and services, monitor and maintain the…',\n",
       " 'Experience with commercial credit data.\\nThe analyst will be conducting analyses and producing reports based on data generated from several different sources and…',\n",
       " \"You will design, build, and maintain Rubrik's cloud data protection services.\\nExperience in data structures, algorithms, software design, and systems analysis.\",\n",
       " 'Relevant multi-year work or academic experience in data science or related fields such as data engineering, data analysis, software engineering, statistics, etc…',\n",
       " 'Strong foundation in data structures, algorithms and software design.\\nUse your technical and creative genius in designing, developing, implementing, and…',\n",
       " 'Experience leading a small team of data or software engineers.\\nDevelop data pipelines adhering with privacy and governance principles.',\n",
       " 'Implement backend data pipelines for manipulating and managing big data.\\nImprove existing data pipelines in terms of scalability and efficiency.',\n",
       " 'Support the implementation of data integration requirements and develop the pipeline of data from raw to curation layers including the cleansing, transformation…',\n",
       " 'Create and maintain the data pipeline architecture for real-time data processing.\\nProficient at building processes supporting data transformation, data…',\n",
       " 'Work closely on a Hadoop based data lake leveraging Spark and Python scripting to efficiently combine data from multiple sources and develop curated data stores…',\n",
       " 'Deep understanding and direct use of big data platforms (Spark, Hadoop, etc.), and data engineering technologies.\\nExperience working with REST APIs is a plus.',\n",
       " 'Build data pipelines to allow design and service engineers to gain insights into product’s field performance.\\nDesign, build and deploy efficient & reliable data…',\n",
       " 'Able to communicate processes and results with all parties involved in the product team, including engineers, product owner, scrum master, third party vendors…',\n",
       " 'It uses common data architecture practices to architect, design, and develop data/analytic platforms (e.g., data warehouses, data lakes) that are used to…',\n",
       " 'Healthcare experience with managing claims data.\\nIn this position you will lead innovation through exploration, benchmarking, making recommendations, and…',\n",
       " 'You will be working on building data pipelines and building workflows on top of productized AI microservices.\\nHacked a non-computer system before.',\n",
       " 'Bonus Points Experience working with very high scale data infrastructure Experience with data products on Google Cloud Platform, Kubernetes, or Airflow Full…',\n",
       " 'Principal Software Engineers are expert engineers with significant technical experience and exposure.\\nMentoring, guiding, and coaching other engineers at the…',\n",
       " 'Developing web applications focusing on data visualization, or data visualization component development.\\nIn depth knowledge of data visualization design and…',\n",
       " 'Data Connections team works as an early stage startup within Amplitude, trying to create a new data platform to support customers collect the right data and…',\n",
       " \"The transaction will enhance the resources and potential of the business' storage solutions, including client and enterprise SSDs, in the rapidly growing NAND…\",\n",
       " 'Knowledge and experience with server and desktop virtualization, software defined solutions, cloud, storage, business continuity, systems management, and data…',\n",
       " 'Design customized data tests to guarantee quality of data model results.\\nExperience with transactional data processing, ETL, data warehouse, data mart, data…',\n",
       " 'This position is responsible for analyzing data and collaborate with business analyst and developers to translate data requirements into logical data models,…',\n",
       " 'Provide consulting for internal teams and clients on data architectures and schemas, data hygiene, and areas for improving process efficiency.',\n",
       " 'Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.\\nOwn core pieces of the Seasoned data platform.',\n",
       " 'Build data expertise and own data quality for allocated areas of ownership.\\nExperience with large data sets, Hadoop, and data visualization tools.',\n",
       " 'Strong attention to details in maintaining data integrity and identifying potential data problems.\\nThe S3VI common web portal will perform data consolidation,…',\n",
       " 'This position is responsible for analyzing data and collaborate with business analyst and developers to translate data requirements into logical data models,…',\n",
       " 'Identify, evaluate and evangelize through data-based evidence improvements to the Data Lake as we as the data processing environment; hence influence the data…',\n",
       " 'Ability to investigate down to data source to ensure accuracy of data.\\nExperience analyzing large scale data sets.\\nDatabase querying skills using SQL.',\n",
       " 'You are a strong, analytically inclined engineer who loves solving complex problems using data.\\nWork in tandem with data science and data engineering teams to…',\n",
       " 'You will work on developing and enhancing our data warehouse, defining processes for data monitoring and alerting as well as maintaining data integrity in our…',\n",
       " '5+ years experience designing and implementing data-driven solutions, such as reporting or data integration systems to align business goals.',\n",
       " 'Experience working with large data sets.\\nBS in computer science, engineering, or applied math with 7+ years practical experience in data science, modeling,…',\n",
       " 'Build and maintain a robust data engineering process to develop and implement self-serve data and tools for Visa’s data scientists.\\nGo lang and Scala is a plus.',\n",
       " 'The data team is made up of 8 data engineers, analysts, and scientists.\\nWe work cross-functionally and fullstack delivering data pipelines, scripting automation…',\n",
       " 'We also serve corporate and university campuses, data centers, high-tech and bio-tech research, medical, manufacturing and warehousing facilities.',\n",
       " 'Build data expertise and own data quality for allocated areas of ownership.\\nWork with product managers and data analysts to build data products that power our…',\n",
       " 'Develop ETL processes to merge data from disparate sources.\\nNinja-level data visualization and spreadsheet storytelling skills.\\n70%+ Pacific time-zone overlap.',\n",
       " 'Be the subject matter expert in all things data pipelines, data lakes and warehouse, tooling & frameworks, integration and sourcing of data.',\n",
       " 'Ability to engineer fault-tolerant distributed systems that move data around without duplicates, missed rows, within api limits.',\n",
       " 'Interface with engineers, product managers and machine learning scientists/engineers to understand data needs and implement robust and scalable solutions.',\n",
       " 'Experience in a regulated environment, ideally within medical devices; medical data analytics (examples include data discovery, pattern recognition, machine…',\n",
       " 'Bachelor’s degree - Computer Science, Electronics, Electrical.\\n3+ years’ relevant experience in the product/platform engineering space.',\n",
       " 'Experience with relational data modeling and metadata management.\\nAnalyze and translate business needs into long-term data models.',\n",
       " \"You have professional experience working with modern data storage and processing technologies, and you've wrangled enough data to understand how often the…\",\n",
       " 'Implement backend data pipelines for manipulating and managing big data.\\nImprove existing data pipelines in terms of scalability and efficiency.',\n",
       " 'Proficiency in SQL, data modeling, and data warehousing.\\nCollaborate with product teams and data analysts to design and build data-forward solutions.',\n",
       " 'Collaborate with multifunctional engineers across the company to help tune the performance of large data applications to drive cost savings.',\n",
       " 'Lead a team of Data Engineers to build, test and refine data pipelines for data analytics and business intelligence (BI).',\n",
       " 'Build data pipelines to consume data from various data sources and create a unified/enterprise data model for analytics and reporting.',\n",
       " 'You are a strong, analytically inclined engineer who loves solving complex problems using data.\\nWork in tandem with data science and data engineering teams to…',\n",
       " 'Perform data quality validations to ensure data creation.\\nAcquire data from primary or secondary data sources and maintain databases/data systems to empower…',\n",
       " 'Able to communicate processes and results with all parties involved in the product team, including engineers, product owner, scrum master, third party vendors…',\n",
       " 'This includes providing data integration services for all batch data movement, managing, and enhancing the data warehouse, Data Lake & data marts, and providing…',\n",
       " 'The ideal candidate has a thorough understanding of data pipeline scalability, has experience with managing distributed data collection systems, and has an…',\n",
       " 'Make data and analytics easily accessible to product and revenue teams to enable data-driven decision making.\\nExperience setting up and/or revamping large parts…',\n",
       " 'Experience using Python or equivalent for data analysis.\\nWe use data collected from our highly connected systems to find problems before the customer does and…',\n",
       " 'You have experience building and maintaining ETLs, data pipelines, and data models.\\nStrong experience with distributed data architectures and big data…',\n",
       " 'Collaborate with software engineers, product managers, other data engineers and data scientists to understand data needs.',\n",
       " 'Design customized data tests to guarantee quality of data model results.\\nExperience with transactional data processing, ETL, data warehouse, data mart, data…',\n",
       " 'Develop protocols and manage the data governance process to promote data standards, data quality & data security.\\nBenefits: medical, dental, vision, 401k.',\n",
       " 'Demonstrated expertise with streaming data.\\nWorking as part of the Data Engineering team responsible for managing data feeds and collecting analytical streaming…',\n",
       " 'Design and delivery of scalable data-driven applications in real-time platforms.\\nAssist in analyzing diverse sets of imperfect data and finding common patterns,…',\n",
       " 'Mentor junior engineers and onboard new engineers.\\nDesign and implement tools to scrape data, validate data, and semi-automate human feedback.',\n",
       " 'Build data expertise and own data quality for allocated areas of ownership.\\nWork with product managers and data analysts to build data products that power our…',\n",
       " 'Interface with engineers, product managers and machine learning scientists/engineers to understand data needs and implement robust and scalable solutions.',\n",
       " 'Work with data and analytics experts to strive for greater functionality in our data systems.\\nKeep our data separated and secure across national boundaries…',\n",
       " '3+ years of experience maintaining data pipelines from multiple data sources, in collaboration with diverse partners.\\n401(k), Maternity & Parental Leave.',\n",
       " 'Training analysts and data scientists alike on available data sources.\\nEnforcing company data policies and procedures to ensure data quality and reduce…',\n",
       " 'Own core company data pipeline, being responsible for scaling up data processing flow to meet rapid data growth.\\nSchedule: Monday - Friday, 40 hours per week.',\n",
       " 'This position is responsible for analyzing data and collaborate with business analyst and developers to translate data requirements into logical data models,…',\n",
       " 'Ability to engineer fault-tolerant distributed systems that move data around without duplicates, missed rows, within api limits.',\n",
       " 'Performs activities related to the creation, implementation, and sustainment of attraction industrial data centers and communications.',\n",
       " 'Develop data monitoring framework to ensure highest data quality.\\nIn collaboration with other data engineers, database administrators, and developers, the…',\n",
       " 'Develop new ETL processes to fulfill the data needs of data science and other departments.\\nEnsure the data collection pipeline and data analysis infrastructure…',\n",
       " 'Contribute to data pipelines that clean, transform and aggregate data from disparate data sources into reporting data stores.',\n",
       " \"Experience in Distributed data processing and hadoop eco system.\\nResponsible for design and development of different products utilizing Visa's huge data.\",\n",
       " 'Expertise with all aspects of data management: data governance, data mastering, meta-data management, data taxonomies and ontologies.',\n",
       " 'Train engineers in advanced manufacturing engineering methods and tools.\\nStandardize and document tools and methods for optimal manufacturing and assembly of…',\n",
       " 'Deep understanding of Big data and Hadoop architecture.\\nStrong knowledge of data structures, algorithms, & distributed systems.\\nJob Types: Part-time, Contract.',\n",
       " 'Partner with other data teams across the Dolby to build data pipelines that transform, aggregate, and integrate Interactivity API data into the central data…',\n",
       " 'Work with our teams of data analysts, machine learning engineers and software engineers to develop data marts that provide convenient access to the data for…',\n",
       " 'Learn and contribute to all aspects of the data platform, from data extraction from external systems to data modeling, transformation, and data management.',\n",
       " 'You have experience building and maintaining ETLs, data pipelines, and data models.\\nStrong experience with distributed data architectures and big data…',\n",
       " 'Detect data quality issues, identify their root causes, implement fixes, and design data audits to capture issues.\\n5+ years of relevant work experience.',\n",
       " 'Develop tools to interface with data pipelines for processing simulation and flight test data.\\nExperience with databases and/or data pipelines.',\n",
       " 'Experience in data modeling for batch processing and streaming data feeds; structured and unstructured data.\\nKnowledge of data management fundamentals and data…',\n",
       " 'Work closely on a Hadoop based data lake leveraging Spark and Python scripting to efficiently combine data from multiple sources and develop curated data stores…',\n",
       " 'Training analysts and data scientists alike on available data sources.\\nEnforcing company data policies and procedures to ensure data quality and reduce…',\n",
       " \"You're familiar with extracting data from different data stores and making it available for analytical and machine learning use cases in data lakes and…\",\n",
       " '3+ years experience as a data engineer or data-focused Software Engineer.\\nBuild highly reliable computed tables (including unstructured data like video and…',\n",
       " 'Ability to engineer fault-tolerant distributed systems that move data around without duplicates, missed rows, within api limits.',\n",
       " 'Deep understanding of data pipelines and data science workflows.\\nDesign and implement production-grade data pipelines utilizing big data and distributed…',\n",
       " 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow.\\nExperience with big data tools: Hadoop, Spark, Kafka, etc.',\n",
       " 'Experience with data security and privacy concerns, ideally with healthcare data.\\nFamiliarity with data governance frameworks.',\n",
       " 'Create and maintain the data pipeline architecture for real-time data processing.\\nProficient at building processes supporting data transformation, data…',\n",
       " '1+ years of experience with ETL, data processing, and data analytics.\\nMaintain and develop data workflows, internal process improvements, and optimize data…',\n",
       " 'Contribute to data pipelines that clean, transform and aggregate data from disparate data sources into reporting data stores.',\n",
       " 'The Data Engineer candidate will build an ETL pipeline of data to supply data to an enterprise data warehouse for analysis by the BI team.',\n",
       " 'Training analysts and data scientists alike on available data sources.\\nEnforcing company data policies and procedures to ensure data quality and reduce…',\n",
       " 'Proficiency in all facets of DW Architecture, data flow strategy, data modeling, metadata and master data management.',\n",
       " 'Support stakeholders with designing data structure for data products.\\nIndustry experience building and productionizing data pipelines.',\n",
       " 'Be the subject matter expert in all things data pipelines, data lakes and warehouse, tooling & frameworks, integration and sourcing of data.',\n",
       " 'You will collaborate with business users, data engineers, and data scientists to bring meaning to the data and help ensure data pipelines are measuring metrics…',\n",
       " 'You will utilize your knowledge of data structures and algorithms to develop highly performant features.\\nThe clean, intuitive, and beautiful user interface you…',\n",
       " 'Good decision-making is only possible when you have trustworthy and reliable data, along with the right tools and systems to process, analyze, and consume that…',\n",
       " 'Partner with other data teams across the Dolby to build data pipelines that transform, aggregate, and integrate Interactivity API data into the central data…',\n",
       " 'Experience with very large-scale data warehouse and data engineering projects.\\nAbility to create data models, STAR schemas for data consuming.',\n",
       " 'Expert with data lake design, data modeling and massive data sets.\\nImplement efficient real-time streaming and data lake batch processes that preserve data…',\n",
       " 'Keen interest in data engineering and designing/developing data-centric solutions.\\nExperience with data manipulation using pandas in python.',\n",
       " 'We integrate multifaceted data streams such as constantly evolving market data, user data based on app activity, and brokerage operations data to perfect our…',\n",
       " 'Hands-on experience developing/maintaining data pipelines (ETL, ELT, streaming data).\\nKnowledge and experience deploying and maintaining data process frameworks…',\n",
       " 'Ability to investigate down to data source to ensure accuracy of data.\\nExperience analyzing large scale data sets.\\nDatabase querying skills using SQL.',\n",
       " 'Strong attention to details in maintaining data integrity and identifying potential data problems.\\nThe S3VI common web portal will perform data consolidation,…',\n",
       " 'We are looking for data engineers who will build, migrate and maintain data pipelines.\\n? Experience building high performance data pipelines.',\n",
       " 'Knowledge of data mining and big data analytics techniques.\\nThis area of responsibility is broad and includes: building ML infrastructure, building analytics…',\n",
       " 'Build scalable data pipelines for data mining and analytics.\\nExperience with ETL or large scale data processing.\\n3+ years experience working with Linux.',\n",
       " \"You will design, build, and maintain Rubrik's cloud data protection services.\\nExperience in data structures, algorithms, software design, and systems analysis.\",\n",
       " 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow.\\nExperience with big data tools: Hadoop, Spark, Kafka, etc.',\n",
       " \"You're familiar with extracting data from different data stores and making it available for analytical and machine learning use cases in data lakes and…\",\n",
       " 'Data Connections team works as an early stage startup within Amplitude, trying to create a new data platform to support customers collect the right data and…',\n",
       " 'Troubleshoot complex operational issues by gathering and analyzing data from various sources.\\nAddress complex problems at both an application and system level.',\n",
       " 'Experience with relational data modeling and metadata management.\\nAnalyze and translate business needs into long-term data models.',\n",
       " 'Design and maintain data storage solutions such as data lakes and data warehouses that allow for large-scale analytics processing.',\n",
       " \"Design and maintain data storage solutions such as data lakes and data warehouses that allow for large-scale analytics processing.\\nThings you're good at.\",\n",
       " \"The transaction will enhance the resources and potential of the business' storage solutions, including client and enterprise SSDs, in the rapidly growing NAND…\",\n",
       " 'Training analysts and data scientists alike on available data sources.\\nEnforcing company data policies and procedures to ensure data quality and reduce…',\n",
       " 'Ability to investigate down to data source to ensure accuracy of data.\\nExperience analyzing large scale data sets.\\nIn this role you will:',\n",
       " 'Expert with data lake design, data modeling and massive data sets.\\nImplement efficient real-time streaming and data lake batch processes that preserve data…',\n",
       " 'Experience with large relational data in various formats.\\nThat is to automate fast, available, and accurate data to super-charge the data science we deliver to…',\n",
       " 'Data Connections team works as an early stage startup within Amplitude, trying to create a new data platform to support customers collect the right data and…',\n",
       " 'Recommended continuous improvements to our data governance practices and implemented data quality improvements.\\nWe Breathe Life Into Data!',\n",
       " 'Automating manual data acquisition processes and optimize data delivery.\\nData integration, data integrity to improve data fidelity for real time analytics.',\n",
       " 'Experience in data cleaning techniques, ETL, and data visualizations.\\nInnovate, design, develop data extraction, transfer and load programs for large data…',\n",
       " \"Support stakeholders with designing data structure for data products.\\nIndustry experience building and productionizing data pipelines.\\nWhat You'll Be Doing:\",\n",
       " 'Have extensive knowledge building data pipelines and infrastructure that can adapt and scale as data volume grows and customer needs evolve.',\n",
       " 'Build data expertise and own data quality for allocated areas of ownership.\\nExperience with large data sets, Hadoop, and data visualization tools.',\n",
       " \"10+ years' of experience in data systems, data engineering, data governance, and data pipelining.\\nExperience building data systems that support ML workflows and…\",\n",
       " 'We are looking for data engineers who will build, migrate and maintain data pipelines.\\nWe are looking for engineers with:\\nNo corp to corp applicants please.',\n",
       " 'Develop and enforce data engineering, security, data quality standards through automation.\\nWork closely with data analysts and business stakeholders to make…',\n",
       " 'Evangelizing high quality data engineering practices towards building data infrastructure, pipelines at scale and fostering the next-gen state of art data…',\n",
       " 'We integrate multifaceted data streams such as constantly evolving market data, user data based on app activity, and brokerage operations data to perfect our…',\n",
       " 'Deep understanding of data pipelines and data science workflows.\\nDesign and implement production-grade data pipelines utilizing big data and distributed…',\n",
       " \"The transaction will enhance the resources and potential of the business' storage solutions, including client and enterprise SSDs, in the rapidly growing NAND…\",\n",
       " '5+ years of professional experience in data engineering.\\nExperience with data visualization tools such as Tableau.\\nCompetitive base salary ($150-170k DOE).',\n",
       " 'You have experience building and maintaining ETLs, data pipelines, and data models.\\nStrong experience with distributed data architectures and big data…',\n",
       " 'Design and maintain data storage solutions such as data lakes and data warehouses that allow for large-scale analytics processing.',\n",
       " 'Experience designing, implementing, and maintaining data systems or tools.\\nFamiliarity with gathering feedback and working with customers of data or tools.',\n",
       " 'Deep understanding and direct use of big data platforms (Spark, Hadoop, etc.), and data engineering technologies.\\nExperience working with REST APIs is a plus.',\n",
       " 'Build data expertise and own data quality for allocated areas of ownership.\\nWork with product managers and data analysts to build data products that power our…',\n",
       " 'As apart of the Data team you will be responsible for building a scalable data ingestion/processing platform and low latency customer facing data APIs.',\n",
       " 'Implement backend data pipelines for manipulating and managing big data.\\nImprove existing data pipelines in terms of scalability and efficiency.',\n",
       " 'Work with data and analytics experts to strive for greater functionality in our data systems.\\nBuild the infrastructure required for optimal extraction,…',\n",
       " 'Ability to engineer fault-tolerant distributed systems that move data around without duplicates, missed rows, within api limits.',\n",
       " 'Collaborate with the data processing team on data related components (e.g., schema design).\\nTest and tune data lake performance.',\n",
       " 'This role also designs and develops large-scale data systems (e.g., databases, data warehouses, big data systems), platforms, and infrastructure for various…',\n",
       " 'Experience building and optimizing ETL data pipelines.\\nIn-depth understanding of data structures, algorithms, and distributed systems.',\n",
       " 'Proficiency in computer science fundamentals such as data structures, algorithms and networking.\\nOptimization of complex manufacturing pipelines using machine…',\n",
       " 'Work with data and analytics experts to strive for greater functionality in our data systems.\\nKeep our data separated and secure across national boundaries…',\n",
       " 'Establish, mentor and advice on data engineering best practices.\\nArchitect, Develop and maintain our data warehouse and analytics database.',\n",
       " 'Experience with data products on Google Cloud Platform.\\nWe operate a petabyte-scale data warehouse and provide tools that empower the machine learning, data…',\n",
       " 'Be the subject matter expert in all things data pipelines, data lakes and warehouse, tooling & frameworks, integration and sourcing of data.',\n",
       " 'Assist with conducting data design, API design and application component architecture.\\nExperience with RDBS and NoSQL Databases such as Postgres, MySQL, Mongo,…',\n",
       " 'We integrate multifaceted data streams such as constantly evolving market data, user data based on app activity, and brokerage operations data to perfect our…',\n",
       " 'Functionally lead team of data engineers to deliver data solutions in Agile manner while mentoring junior-level data engineers.',\n",
       " 'Server and network hardware troubleshooting, followed by physical repair or replacement.\\nPerform initial configuration of servers and network devices and…',\n",
       " 'Support day-to-day operations and escalations of the overall virtual desktop environment and network.\\nImprove and optimize system administration and management…',\n",
       " 'Experience with relational data modeling and metadata management.\\nAnalyze and translate business needs into long-term data models.',\n",
       " 'Experience with data engineering - ETL Pipelines, Data Lakes, Database Management, etc.\\nYou are excited to work with and learn from software, mechanical,…']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries14_noreturn = [word.replace('\\n',' ') for word in summaries14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Synaptein Solutions</td>\n",
       "      <td>Thousand Oaks, CA</td>\n",
       "      <td>Proven proficiency with scripting languages su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer III</td>\n",
       "      <td>Ursus</td>\n",
       "      <td>Menlo Park, CA 94025+1 location</td>\n",
       "      <td>Experience with ETL processes, extracting data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>San Francisco, CA+1 location</td>\n",
       "      <td>Using programming skills to create data pipeli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate, Visualization Data Engineer</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>Los Angeles, CA 90071 (Downtown area)</td>\n",
       "      <td>Proficient with data management and integratio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer, Growth</td>\n",
       "      <td>Square</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Understand and implement data logging best pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Principal Data Engineer, JLL Technologies</td>\n",
       "      <td>JLL</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Functionally lead team of data engineers to de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>Sr. Data Center Infrastructure Engineer</td>\n",
       "      <td>Zscaler</td>\n",
       "      <td>San Jose, CA 95134 (North San Jose area)</td>\n",
       "      <td>Server and network hardware troubleshooting, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Data Center Facilities Engineering, Systems En...</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Fremont, CA 94555 (Northgate area)</td>\n",
       "      <td>Support day-to-day operations and escalations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Data Science - Analytics Engineer</td>\n",
       "      <td>Resonance AI</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Experience with relational data modeling and m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Software Engineer, Data Engineering</td>\n",
       "      <td>Neuralink</td>\n",
       "      <td>Fremont, CA</td>\n",
       "      <td>Experience with data engineering - ETL Pipelin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title         company_name  \\\n",
       "0                                        Data Engineer  Synaptein Solutions   \n",
       "1                                    Data Engineer III                Ursus   \n",
       "2                                        Data Engineer              Harnham   \n",
       "3               Associate, Visualization Data Engineer                 KPMG   \n",
       "4                                Data Engineer, Growth               Square   \n",
       "..                                                 ...                  ...   \n",
       "505          Principal Data Engineer, JLL Technologies                  JLL   \n",
       "506            Sr. Data Center Infrastructure Engineer              Zscaler   \n",
       "507  Data Center Facilities Engineering, Systems En...             Facebook   \n",
       "508                  Data Science - Analytics Engineer         Resonance AI   \n",
       "509                Software Engineer, Data Engineering            Neuralink   \n",
       "\n",
       "                                     location  \\\n",
       "0                           Thousand Oaks, CA   \n",
       "1             Menlo Park, CA 94025+1 location   \n",
       "2                San Francisco, CA+1 location   \n",
       "3       Los Angeles, CA 90071 (Downtown area)   \n",
       "4                           San Francisco, CA   \n",
       "..                                        ...   \n",
       "505                         San Francisco, CA   \n",
       "506  San Jose, CA 95134 (North San Jose area)   \n",
       "507        Fremont, CA 94555 (Northgate area)   \n",
       "508                         San Francisco, CA   \n",
       "509                               Fremont, CA   \n",
       "\n",
       "                                               summary  \n",
       "0    Proven proficiency with scripting languages su...  \n",
       "1    Experience with ETL processes, extracting data...  \n",
       "2    Using programming skills to create data pipeli...  \n",
       "3    Proficient with data management and integratio...  \n",
       "4    Understand and implement data logging best pra...  \n",
       "..                                                 ...  \n",
       "505  Functionally lead team of data engineers to de...  \n",
       "506  Server and network hardware troubleshooting, f...  \n",
       "507  Support day-to-day operations and escalations ...  \n",
       "508  Experience with relational data modeling and m...  \n",
       "509  Experience with data engineering - ETL Pipelin...  \n",
       "\n",
       "[510 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_list_max4_df = pd.DataFrame(list(zip(jobs14, companies14, locations14, summaries14_noreturn)),\n",
    "               columns = ['job_title', 'company_name', 'location', 'summary'])\n",
    "job_list_max4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list_max4_df.to_csv('job_list_engineer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
